{
  "batch_id": "20251223_021239",
  "timestamp": "2025-12-23T02:14:00.808072",
  "papers": [
    {
      "id": "e4dc71eb-6bee-4eba-9004-157f56f6ca52",
      "arxiv_id": "neurips2025.D1Iw4Unvfc",
      "title": "ReAgent-V: A Reward-Driven Multi-Agent Framework for Video Understanding"
    },
    {
      "id": "c0ec2a55-6173-4d1a-b1eb-10c559adcc1b",
      "arxiv_id": "neurips2025.zsUOQRUFOy",
      "title": "Accelerating Feature Conformal Prediction via Taylor Approximation"
    },
    {
      "id": "3176200f-643d-43d6-9636-6a9e9715ce6f",
      "arxiv_id": "neurips2025.wdI2WKCN3P",
      "title": "HoT-VI: Reparameterizable Variational Inference for Capturing Instance-Level High-Order Correlations"
    },
    {
      "id": "fbbd6f1b-ef94-418b-b5cb-06cdcde8f934",
      "arxiv_id": "neurips2025.MhOhzdjK0e",
      "title": "Deep learning for continuous-time stochastic control with jumps"
    },
    {
      "id": "bf59306d-90e9-4b1a-86a4-63d847aa77a1",
      "arxiv_id": "neurips2025.LamTzqRHvL",
      "title": "Planning with Quantized Opponent Models"
    }
  ],
  "translations": {
    "fbbd6f1b-ef94-418b-b5cb-06cdcde8f934": {
      "title_zh": "基于深度学习的带跳跃连续时间随机控制",
      "summary_zh": "本文提出一种基于模型的深度学习方法，用于求解有限时域带跳跃的连续时间随机控制问题。通过迭代训练两个神经网络：一个用于表示最优策略，另一个用于逼近价值函数。借助动态规划原理的连续时间形式，我们基于哈密顿-雅可比-贝尔曼方程推导出两种不同的训练目标，确保网络能够捕捉底层随机动态特性。在不同问题上的实证评估表明，该方法具有较高的精确度与可扩展性，能有效解决复杂的高维随机控制任务。"
    },
    "3176200f-643d-43d6-9636-6a9e9715ce6f": {
      "title_zh": "HoT-VI：面向实例级高阶相关性建模的可重参数化变分推断",
      "summary_zh": "均值场变分推断虽具有可扩展性，但其独立性假设存在局限，不适用于数据实例存在相关性的场景。现有的结构化变分推断方法要么关注隐维度间的相关性（缺乏对实例级相关性建模的可扩展性），要么局限于简单的一阶依赖关系，限制了其表达能力。本文提出高阶树结构变分推断方法，显式建模隐变量间的k阶实例级相关性。通过使用重叠的k维局部边际分布表示全局后验分布，本方法实现了基于顺序采样过程的高效参数化采样。为确保这些边际分布的有效性，我们提出一种条件相关性参数化方法，保障其相关矩阵的正定性。进一步通过树结构主干扩展本方法，以捕捉更灵活的依赖模式。在时间序列与图结构数据集上的大量实验表明，建模高阶相关性能显著提升后验近似质量，并在多种下游任务中取得更优性能。"
    },
    "c0ec2a55-6173-4d1a-b1eb-10c559adcc1b": {
      "title_zh": "基于泰勒近似的特征共形预测加速方法",
      "summary_zh": "共形预测因其具有事后性、无分布性和模型无关性等特点，在不确定性量化领域得到广泛应用。在现代深度学习研究中，学者提出了特征共形预测方法，通过在特征空间部署共形预测来获得更窄的置信带宽度。然而，由于需要耗时的非线性操作将置信带从特征空间转换到输出空间，特征共形预测的实际应用受到限制。本文提出快速特征共形预测方法，通过采用一阶泰勒展开近似这些非线性操作来实现加速。该方法提出了一种新颖的非一致性评分函数，在实际应用中兼具效能与效率。实验验证表明，快速特征共形预测在回归和分类任务中均能达到与特征共形预测相当的性能（两者均优于原始方法），同时计算时间显著减少约50倍。"
    },
    "bf59306d-90e9-4b1a-86a4-63d847aa77a1": {
      "title_zh": "基于量化对手模型的规划方法",
      "summary_zh": "在多智能体环境中，对手不确定性下的规划是一项根本性挑战：智能体必须在推断对手隐含策略的同时采取行动。现有的基于类型的方法依赖人工定义的行为类别且难以扩展，而无模型方法则存在样本效率低下、缺乏将不确定性系统化融入规划流程的理论框架等问题。本文提出量化对手模型，通过量化自编码器学习紧凑的对手类型目录，并在在线过程中维护基于这些类型的贝叶斯信念。该后验分布既可支持基于信念加权的元策略，也能驱动直接融合不确定性的蒙特卡洛规划算法，从而实现实时信念更新与定向探索。实验表明，量化对手模型能以更低的搜索成本获得更优性能，为信念感知规划提供了可行且高效的解决方案。"
    },
    "e4dc71eb-6bee-4eba-9004-157f56f6ca52": {
      "title_zh": "ReAgent-V：一种面向视频理解的奖励驱动多智能体框架",
      "summary_zh": "视频理解是行为识别、视频推理与机器人控制等任务的基础。早期的视频理解方法通常基于大型视觉-语言模型，采用单次推理范式且缺乏动态反馈，限制了模型在复杂场景中的自我修正与适应能力。近期研究尝试通过引入奖励模型与强化学习增强推理能力，或采用工具-智能体框架以突破此局限，但仍面临标注成本高、奖励信号难以捕捉实时推理状态、推理效率低等挑战。为应对这些问题，本文提出ReAgent-V——一种新型智能体化视频理解框架，该框架在推理过程中将高效帧选择与实时奖励生成相结合。这些奖励信号不仅能通过多视角反思机制（从保守、中立和激进视角调整预测）指导答案的迭代优化，还能为监督微调、直接偏好优化和群组相对策略优化自动筛选高质量数据。ReAgent-V具有轻量化、模块化和可扩展的特点，支持根据多样化任务灵活集成工具。我们在三大核心应用场景（视频理解、视频推理增强、视觉-语言-动作模型对齐）的12个数据集上进行广泛实验，结果表明该框架在泛化能力和推理性能上均有显著提升，分别达到最高6.9%、2.1%和9.8%的改进，充分体现了所提框架的有效性与通用性。"
    }
  },
  "interpretations": {
    "c0ec2a55-6173-4d1a-b1eb-10c559adcc1b": "## 研究背景\n在深度学习中，模型的预测往往过于自信，缺乏对不确定性的量化。这在实际应用中很危险，例如在自动驾驶中，模型需要知道自己何时“不确定”以避免事故。传统的共形预测是一种强大的工具，它能以数学上严谨的方式，为任何预测模型（如神经网络）生成一个可信的区间（例如“这只猫的体重在3到5公斤之间”），且无需假设数据分布。\n\n然而，标准方法生成的区间可能较宽。为此，研究者提出了特征共形预测，它将数据映射到一个更具判别力的“特征空间”中进行计算，从而得到更精确的区间。但问题在于：计算出的特征空间区间，需要通过复杂的非线性网络层反变换回原始输出空间（如图像类别或具体数值），这个过程极其耗时，限制了其实用性。\n\n## 核心方法\n本文的核心思想是**用一次快速的“线性估计”来代替耗时的“精确计算”**。想象一下：你想知道拉长一根橡皮筋（非线性变换）后某点的精确位置，但精确计算很慢。一个聪明的办法是，在橡皮筋的初始位置做标记，然后假设它被均匀拉伸（线性近似），快速估算出新位置。虽然不完全精确，但在局部小范围内足够接近。\n\n具体而言，该方法利用了数学中的**一阶泰勒展开**。它将复杂的非线性变换函数，在当前数据点附近用一个简单的**线性函数（切线）来近似**。这个线性近似只需要计算一次函数梯度和函数值，后续所有数据的变换都通过这个线性公式快速完成，完全避免了重复运行沉重的神经网络。基于此，作者设计了一种新的“非共形分数”，它能高效地结合这种近似，确保最终预测区间的可靠性。\n\n## 主要贡献\n本文提出的快速特征共形预测方法，在几乎不牺牲预测精度的情况下，实现了计算速度的**巨大飞跃**。实证结果表明，在回归和分类任务上，新方法取得的预测区间质量与原有的特征共形预测相当（两者均显著优于原始方法），但**计算时间缩短了约50倍**。\n\n这一贡献的意义在于，它将一个理论上优秀但计算成本高昂的方法，变成了一个可应用于现实场景的实用工具。对于需要快速、可靠不确定性估计的领域（如医疗诊断、金融风险评估、实时机器人控制），该方法提供了高效的解决方案，极大地推动了可靠人工智能的实际部署。",
    "fbbd6f1b-ef94-418b-b5cb-06cdcde8f934": "## 研究背景\n想象你需要在瞬息万变的金融市场中做出连续的投资决策，价格不仅会平滑波动，还可能突然“跳跃”（如突发新闻导致股价剧变）。这就是“带跳跃的连续时间随机控制问题”。它是金融、工程等领域的关键数学模型，但求解极其困难。传统方法（如求解复杂的哈密顿-雅可比-贝尔曼方程）在问题维度稍高或跳跃结构复杂时，就会因“维度灾难”而束手无策，计算变得不可行。因此，亟需一种能处理高维复杂场景的新方法。\n\n## 核心方法\n本文的核心巧思是：**用两个神经网络“学生”，一个学习“怎么操作”（策略），一个评估“结果多好”（价值函数），并让它们相互教学、共同进步**。\n\n具体而言，作者构建了一个基于模型的深度学习框架：\n1.  **策略网络**：充当“决策者”，它观察当前系统状态（如投资组合），直接输出应执行的最优控制动作（如买卖数量）。\n2.  **价值网络**：充当“评分员”，它估计从当前状态开始，遵循现有策略直到结束所能获得的总期望回报。\n\n**训练的关键**在于利用了连续时间动态规划原理。这好比为两位“学生”设计了一套科学的“考题”（训练目标）：\n*   价值网络的训练目标是使其输出满足 **哈密顿-雅可比-贝尔曼方程**——这是最优性必须满足的数学条件。网络通过最小化与该条件的偏差来学习准确“评分”。\n*   策略网络的训练目标则是直接**最大化价值网络给出的评分**。决策者不断调整自己的行为，以争取评分员给出更高的分数。\n\n通过反复迭代这个“决策-评分-改进”的循环，两个网络协同进化，最终共同逼近真实的最优解。这种方法巧妙地将复杂的数学优化问题，转化为了神经网络能够处理的学习任务。\n\n## 主要贡献\n本文提出的方法在实际测试中展现了显著优势：\n1.  **准确性高**：在多个经典测试问题上，该方法得到的解与传统数值方法的结果高度吻合，验证了其求解的精确性。\n2.  **可扩展性强（核心突破）**：它成功解决了传统方法难以处理的高维度、跳跃结构复杂的控制问题。这意味着该方法能够应用于更贴近现实的场景，比如涉及大量资产的投资组合管理或复杂系统的实时调控。\n3.  **提供通用框架**：该工作为求解一类广泛的连续时间随机控制问题提供了一个基于深度学习的统一、灵活的框架，为后续研究与应用开辟了新的路径。",
    "3176200f-643d-43d6-9636-6a9e9715ce6f": "## 研究背景\n想象一下，你想用机器学习模型理解一组相关的数据，比如连续几天的气温变化，或者社交网络中朋友之间的关系。传统的“平均场变分推断”方法为了计算高效，做了一个很强的假设：它认为所有数据点背后的隐藏因素都是彼此**独立**的。这就像分析一个团队时，坚持认为每个成员的行为完全不受队友影响一样，显然不符合现实。之前一些试图建立关联的改进方法也有局限：要么只能刻画数据**内部特征**之间的关联（无法处理数据点之间的关联），要么只能捕捉非常简单的、点对点的（一阶）依赖关系。这就好比用只能连接两个点的直线，去描绘一幅需要复杂曲线才能表达的图画，表达能力严重不足。\n\n## 核心方法\n这篇论文的核心创新是一种名为 **HoT-VI** 的方法。它的巧妙思路可以用“拼图”来类比：\n1.  **从局部到全局**：与其直接估算整个复杂数据集（全局后验）这个“大拼图”，HoT-VI 选择先估算许多个小的、**相互重叠的k维局部拼图块**（即k阶的局部边际分布）。例如，在时间序列中，一个“局部块”可能是连续三天的数据。这些块之间有重叠，确保了整体的一致性。\n2.  **可重参数化的采样**：通过一种特殊的顺序采样程序，可以从这些定义好的局部块中，高效地“组装”出整个数据集的样本。这保证了方法的可扩展性。\n3.  **确保“拼图块”合理**：要定义这些局部块，需要设定它们的相关性矩阵。作者设计了一种**条件相关参数化**方法，能自动保证这些矩阵是“正定”的（这是一个数学上的必要条件，确保了概率分布是有效的），从而避免了手动调整的麻烦。\n4.  **引入树状结构**：为了更灵活地捕捉数据间复杂的依赖模式（不局限于简单的链式结构），方法还扩展了一个树状结构的主干，让局部块能以更丰富的方式连接起来。\n\n## 主要贡献\n该方法在时间序列和图结构数据集上进行了大量实验，证明了其有效性：\n1.  **显著提升近似精度**：通过显式建模实例间的高阶（k>1）相关性，HoT-VI 对真实后验分布的近似程度远优于仅假设独立或只建模一阶相关性的方法。这意味着模型对数据生成机制的理解更准确。\n2.  **在下游任务中表现更好**：由于获得了更高质量的后验分布，基于该分布进行的预测、重构等下游任务性能也获得了系统性提升。这证明了更好的不确定性建模能直接带来更优的实用效果。\n3.  **在效率与表达力间取得平衡**：该方法保持了变分推断计算可扩展的优点，同时极大地增强了对复杂依赖关系的建模能力，为解决相关实例的推断问题提供了一个强有力的新工具。",
    "e4dc71eb-6bee-4eba-9004-157f56f6ca52": "## 研究背景\n视频理解（如识别动作、回答关于视频的问题）是人工智能的重要任务。传统的大型视觉语言模型处理视频时，通常采用“单次推理”模式：看一遍视频，直接给出最终答案。这就像考试时只许你读一遍题目就交卷，没有检查或修改的机会，因此在复杂场景下容易出错。近来，研究者尝试引入“奖励模型”和强化学习来改进，但这需要大量人工标注数据来告诉模型什么是对错，成本高昂。此外，这些奖励信号往往无法反映模型推理过程中的实时状态，且整个系统运行效率较低。因此，如何让模型在推理时能自我纠正、自我适应，同时避免高昂成本，成为一个关键难题。\n\n## 核心方法\n这篇论文提出了一个名为ReAgent-V的新框架，其核心是一个“多智能体”系统，包含两个巧妙的设计，让模型在推理时能自我迭代和优化。\n\n首先，它像一个高效的“剪辑师”，不是机械地处理所有视频帧，而是智能地选择关键帧进行分析。这大大节省了计算资源，提高了效率。\n\n其次，也是最核心的，它在推理过程中**实时生成奖励信号**来指导自己。你可以把它想象成模型内部有三个拥有不同性格的“顾问”在进行辩论：一个保守派（倾向于安全答案），一个中立派，一个激进派（倾向于大胆答案）。模型会综合这三个视角，生成一个初步答案。然后，它会根据实时生成的奖励信号（就像一位内部裁判）对这个答案进行反思和评估。如果得分不高，模型就会调整三位“顾问”的权重，从新的角度重新思考，生成修正后的答案。这个过程可以迭代多次，直到得到一个满意的最终答案。这种自我反思和修正的能力，是其强大之处。\n\n## 主要贡献\n该框架在三个核心应用领域的12个数据集上进行了测试，均取得了显著提升：在**视频理解**任务上性能最高提升6.9%，在**视频推理增强**上提升2.1%，在**视觉-语言-动作模型对齐**上更是提升了9.8%。这些数字证明了其有效性和强大的泛化能力。\n\n除了性能提升，其贡献还体现在两方面：\n1.  **自我驱动的高效学习**：推理过程中产生的奖励信号和高品质答案，可以被自动筛选出来，作为训练数据来进一步优化模型本身。这形成了一个“越用越聪明”的良性循环，降低了对昂贵人工标注数据的依赖。\n2.  **灵活与轻量**：该框架被设计成模块化、可扩展的。这意味着它可以方便地接入各种专业工具（如物体检测器、文本摘要工具等），以适应不同的任务需求，同时保持了轻量级的特性，易于部署和应用。",
    "bf59306d-90e9-4b1a-86a4-63d847aa77a1": "## 研究背景\n在像星际争霸、足球游戏等复杂的多智能体环境中，一个智能体要想做出好的决策，必须推断隐藏的对手正在采取什么策略（即对手的“类型”），这被称为“对手不确定性下的规划”。过去主要有两种方法：一种是“基于类型的方法”，需要研究者预先手动定义所有可能的对手行为模式，这就像试图为对手编写一本死板的“行为字典”——在复杂现实中，这本字典既难写全，也难扩展。另一种是“无模型方法”，它像通过大量随机试错来学习，效率很低，且没有一个系统性的办法在决策过程中考虑“对手可能是谁”这种不确定性。\n\n## 核心方法\n本文提出了“量化对手模型”，其核心是一个两步走的巧妙思路。第一步是**构建“类型图鉴”**：研究者使用一个“量化自编码器”来分析大量历史对手数据。这个网络会自动将千变万化的对手行为，压缩归类成一小撮（例如几十个）最具代表性的“行为原型”。这就像从无数张动物照片中，自动总结出“猫”、“狗”、“鸟”等几个基本类别，形成一本精简的“图鉴”。第二步是**在线“信念追踪”与规划**：在实际对局中，智能体会像一个侦探一样，根据观察到的对手新行动，实时更新它认为对手属于“图鉴”中各个类型的概率（即贝叶斯信念）。这个动态的“信念仪表盘”直接驱动两种决策：一是快速选择一个基于信念加权的混合策略（“元策略”）；二是指导一个蒙特卡洛树搜索算法，在模拟未来时专注于那些高概率的对手类型进行推演，从而实现高效的、有重点的探索。\n\n## 主要贡献\n该方法在实验中取得了显著的实际改进。具体表现在：1. **性能更优**：在标准的策略对抗测试中，QOM智能体最终获得的胜率和累积奖励超越了多种先进的基线方法。2. **搜索成本更低**：由于其规划算法能利用紧凑的“类型图鉴”和聚焦的信念来引导搜索，它不需要进行海量、盲目的未来情景模拟，因此计算开销和搜索时间显著降低，实现了更高效的实时决策。总的来说，QOM为多智能体规划提供了一个既在理论上（原则性地处理不确定性）站得住脚，又在实践上（计算可负担、效果更好）行之有效的新方案。"
  }
}