#!/usr/bin/env python3
"""
ä¸ºæŒ‡å®šçš„16ç¯‡NeurIPSè®ºæ–‡ç”Ÿæˆç¼ºå¤±çš„ç¿»è¯‘å’ŒAIè§£è¯»
"""
import sys
import os
import json
from pathlib import Path
from datetime import datetime
import uuid

# æ·»åŠ backendè·¯å¾„åˆ°sys.path
backend_path = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(backend_path))

from sqlalchemy import text
from sqlalchemy.orm import Session
from loguru import logger

from app.db.session import SessionLocal
from app.models import Paper, PaperTranslation, PaperInterpretation
from app.services.content_generation.translation_generate_v2 import generate_translations_for_papers
from app.services.content_generation.ai_interpretation_generate_v2 import generate_interpretations_for_papers

# éœ€è¦å¤„ç†çš„16ç¯‡è®ºæ–‡ID
MISSING_PAPERS = [
    'b8b00dbc-cfb6-4e30-9ea4-451b9db7627c',  # éœ€è¦ç¿»è¯‘
    'd7d30888-50e4-4601-891f-7e83b5402b11',  # éœ€è¦ç¿»è¯‘
    'd810d631-8432-4ed4-9004-209efdaf42a1',  # éœ€è¦AIè§£è¯»
    'd0d3a0f3-57e0-4092-8a7c-23c549eb854d',  # éœ€è¦ç¿»è¯‘
    '080bd375-f12c-4281-b8f9-4a25de68ef0c',  # éœ€è¦ç¿»è¯‘
    '7792523a-deb3-4679-8ec9-bc134f117bb3',  # éœ€è¦ç¿»è¯‘
    '9ab9992e-bf61-4356-8841-3f666ae868ff',  # éœ€è¦ç¿»è¯‘
    'cf6ebd5e-3f7e-43ae-8fc8-00ab01899c15',  # éœ€è¦AIè§£è¯»
    '5acda317-f2b2-4e4c-8bc8-f3202ac98f0f',  # éœ€è¦ç¿»è¯‘
    'da3d1f6a-7777-4b9b-acf1-ac4c801c4f79',  # éœ€è¦ç¿»è¯‘
    'acdf9d39-aca1-4e74-b927-fd41f314acc5',  # éœ€è¦ç¿»è¯‘
    '273030d5-a4c7-4066-b4a5-15792544a6a5',  # éœ€è¦ç¿»è¯‘
    '10a11f07-1840-4a2c-ad66-29991a260f02',  # éœ€è¦ç¿»è¯‘
    '03406616-29e6-4d93-9eba-f8b5f94f8097',  # éœ€è¦ç¿»è¯‘
    'c2002268-92a9-4290-a491-635509c743e0',  # éœ€è¦ç¿»è¯‘
    '2de16e0b-a99a-4b30-bce7-cb297b8aca69',  # éœ€è¦ç¿»è¯‘
]

def get_papers_needing_translation(session: Session) -> list[Paper]:
    """è·å–éœ€è¦ç¿»è¯‘çš„è®ºæ–‡"""
    papers_needing_translation = []
    
    for paper_id in MISSING_PAPERS:
        # æ£€æŸ¥æ˜¯å¦ç¼ºå°‘ç¿»è¯‘
        translation_query = text("""
            SELECT COUNT(*) FROM paper_translations 
            WHERE paper_id = :paper_id AND title_zh IS NOT NULL
        """)
        has_translation = session.execute(translation_query, {"paper_id": paper_id}).scalar() > 0
        
        if not has_translation:
            paper = session.get(Paper, uuid.UUID(paper_id))
            if paper:
                papers_needing_translation.append(paper)
    
    return papers_needing_translation

def get_papers_needing_interpretation(session: Session) -> list[Paper]:
    """è·å–éœ€è¦AIè§£è¯»çš„è®ºæ–‡"""
    papers_needing_interpretation = []
    
    for paper_id in MISSING_PAPERS:
        # æ£€æŸ¥æ˜¯å¦ç¼ºå°‘AIè§£è¯»
        interpretation_query = text("""
            SELECT COUNT(*) FROM paper_interpretations 
            WHERE paper_id = :paper_id AND interpretation IS NOT NULL
        """)
        has_interpretation = session.execute(interpretation_query, {"paper_id": paper_id}).scalar() > 0
        
        if not has_interpretation:
            paper = session.get(Paper, uuid.UUID(paper_id))
            if paper:
                papers_needing_interpretation.append(paper)
    
    return papers_needing_interpretation

def main():
    logger.info("ğŸš€ å¼€å§‹ä¸º16ç¯‡ç¼ºå¤±TTSçš„NeurIPSè®ºæ–‡ç”Ÿæˆå†…å®¹")
    
    session = SessionLocal()
    
    try:
        # 1. ç”Ÿæˆç¼ºå¤±çš„ç¿»è¯‘
        papers_needing_translation = get_papers_needing_translation(session)
        logger.info(f"ğŸ“ éœ€è¦ç”Ÿæˆç¿»è¯‘çš„è®ºæ–‡: {len(papers_needing_translation)} ç¯‡")
        
        if papers_needing_translation:
            logger.info("å¼€å§‹ç”Ÿæˆç¿»è¯‘...")
            translation_results = generate_translations_for_papers(
                papers=papers_needing_translation,
                max_workers=10  # ä½¿ç”¨10ä¸ªå¹¶å‘
            )
            
            # ä¿å­˜ç¿»è¯‘ç»“æœåˆ°æ•°æ®åº“
            saved_count = 0
            for paper_id, (title_zh, summary_zh) in translation_results.items():
                try:
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç¿»è¯‘è®°å½•
                    existing = session.query(PaperTranslation).filter_by(paper_id=paper_id).first()
                    if existing:
                        existing.title_zh = title_zh
                        existing.summary_zh = summary_zh
                        existing.model_name = "deepseek-reasoner"
                    else:
                        translation = PaperTranslation(
                            paper_id=paper_id,
                            title_zh=title_zh,
                            summary_zh=summary_zh,
                            model_name="deepseek-reasoner"
                        )
                        session.add(translation)
                    saved_count += 1
                except Exception as e:
                    logger.error(f"ä¿å­˜ç¿»è¯‘å¤±è´¥: {paper_id}, {e}")
            
            session.commit()
            logger.info(f"ç¿»è¯‘ç”Ÿæˆå®Œæˆ: ç”Ÿæˆ {len(translation_results)} ç¯‡ï¼Œä¿å­˜ {saved_count} ç¯‡")
        
        # 2. ç”Ÿæˆç¼ºå¤±çš„AIè§£è¯»
        papers_needing_interpretation = get_papers_needing_interpretation(session)
        logger.info(f"ğŸ¤– éœ€è¦ç”ŸæˆAIè§£è¯»çš„è®ºæ–‡: {len(papers_needing_interpretation)} ç¯‡")
        
        if papers_needing_interpretation:
            logger.info("å¼€å§‹ç”ŸæˆAIè§£è¯»...")
            interpretation_results = generate_interpretations_for_papers(
                papers=papers_needing_interpretation,
                max_workers=10  # ä½¿ç”¨10ä¸ªå¹¶å‘
            )
            
            # ä¿å­˜AIè§£è¯»ç»“æœåˆ°æ•°æ®åº“
            saved_count = 0
            for paper_id, interpretation in interpretation_results.items():
                try:
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨è§£è¯»è®°å½•
                    existing = session.query(PaperInterpretation).filter_by(paper_id=paper_id).first()
                    if existing:
                        existing.interpretation = interpretation
                        existing.model_name = "deepseek-reasoner"
                    else:
                        interp = PaperInterpretation(
                            paper_id=paper_id,
                            interpretation=interpretation,
                            model_name="deepseek-reasoner"
                        )
                        session.add(interp)
                    saved_count += 1
                except Exception as e:
                    logger.error(f"ä¿å­˜AIè§£è¯»å¤±è´¥: {paper_id}, {e}")
            
            session.commit()
            logger.info(f"AIè§£è¯»ç”Ÿæˆå®Œæˆ: ç”Ÿæˆ {len(interpretation_results)} ç¯‡ï¼Œä¿å­˜ {saved_count} ç¯‡")
        
        # 3. éªŒè¯ç»“æœ
        logger.info("ğŸ” éªŒè¯ç”Ÿæˆç»“æœ...")
        complete_papers = 0
        
        for paper_id in MISSING_PAPERS:
            # æ£€æŸ¥æ˜¯å¦åŒæ—¶æœ‰ç¿»è¯‘å’Œè§£è¯»
            check_query = text("""
                SELECT 
                    (SELECT COUNT(*) FROM paper_translations pt WHERE pt.paper_id = :paper_id AND pt.title_zh IS NOT NULL) as has_translation,
                    (SELECT COUNT(*) FROM paper_interpretations pi WHERE pi.paper_id = :paper_id AND pi.interpretation IS NOT NULL) as has_interpretation
            """)
            result = session.execute(check_query, {"paper_id": paper_id}).fetchone()
            
            if result.has_translation > 0 and result.has_interpretation > 0:
                complete_papers += 1
        
        logger.info(f"âœ… å®Œæˆå†…å®¹ç”Ÿæˆçš„è®ºæ–‡: {complete_papers}/{len(MISSING_PAPERS)} ç¯‡")
        
        if complete_papers == len(MISSING_PAPERS):
            logger.info("ğŸ‰ æ‰€æœ‰16ç¯‡è®ºæ–‡çš„å†…å®¹éƒ½å·²å®Œæˆï¼Œç°åœ¨å¯ä»¥ç”ŸæˆTTSäº†ï¼")
        else:
            logger.warning(f"âš ï¸  è¿˜æœ‰ {len(MISSING_PAPERS) - complete_papers} ç¯‡è®ºæ–‡éœ€è¦è¡¥å……å†…å®¹")
        
    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆè¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    finally:
        session.close()

if __name__ == "__main__":
    main()
