#!/usr/bin/env python3
"""
å®Œæ•´çš„å†…å®¹ç”Ÿæˆæµ‹è¯•è„šæœ¬

åŒ…å«AIè§£è¯»ä¿å­˜é€»è¾‘
"""
import os
import sys
from pathlib import Path

# ç¦ç”¨ä»£ç†
os.environ.pop('http_proxy', None)
os.environ.pop('https_proxy', None)
os.environ.pop('HTTP_PROXY', None)
os.environ.pop('HTTPS_PROXY', None)
os.environ.pop('all_proxy', None)
os.environ.pop('ALL_PROXY', None)

# æ·»åŠ backendæ ¹ç›®å½•åˆ°è·¯å¾„
backend_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(backend_root))

import pendulum
from sqlalchemy.orm import Session
from sqlalchemy import text, select
from app.db.session import SessionLocal
from app.services.data_ingestion.arxiv_candidate_pool import CandidatePoolServiceV2
from app.services.content_generation.translation_generate import translate_and_save_papers
from app.services.content_generation.ai_interpretation_generate import batch_generate_interpretations
from app.services.content_generation.tts_generate import clean_markdown_for_tts
from app.models import PaperInterpretation
import asyncio
import edge_tts


async def generate_single_tts_async(content: str, voice: str = "zh-CN-XiaoxiaoNeural") -> bytes:
    """å¼‚æ­¥ç”Ÿæˆå•ç¯‡TTS"""
    communicate = edge_tts.Communicate(content, voice)
    audio_bytes = b""
    
    async for chunk in communicate.stream():
        if chunk["type"] == "audio":
            audio_bytes += chunk["data"]
    
    return audio_bytes


def save_interpretations_to_db(session: Session, interpretation_results: dict):
    """ä¿å­˜AIè§£è¯»åˆ°æ•°æ®åº“"""
    saved_count = 0
    
    for paper_id, interpretation in interpretation_results.items():
        try:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            existing = session.scalar(
                select(PaperInterpretation).where(PaperInterpretation.paper_id == paper_id)
            )
            
            if existing:
                existing.interpretation = interpretation
                existing.model_name = "deepseek-chat"
            else:
                new_interpretation = PaperInterpretation(
                    paper_id=paper_id,
                    interpretation=interpretation,
                    language="zh",
                    model_name="deepseek-chat"
                )
                session.add(new_interpretation)
            
            saved_count += 1
        except Exception as e:
            print(f"ä¿å­˜AIè§£è¯»å¤±è´¥: {paper_id}, {e}")
    
    session.commit()
    return saved_count


def main():
    print("=== å®Œæ•´å†…å®¹ç”Ÿæˆæµ‹è¯• ===")
    
    target_date = (pendulum.today() - pendulum.duration(days=3)).date()
    print(f"ä½¿ç”¨æ—¥æœŸ: {target_date}")
    
    db = SessionLocal()
    
    try:
        # 1. è·å–CSå€™é€‰æ± è®ºæ–‡
        print("\nğŸ“‹ è·å–CSå€™é€‰æ± è®ºæ–‡...")
        paper_ids = CandidatePoolServiceV2.get_candidate_papers_by_date(
            session=db,
            target_date=target_date,
            filter_type='cs'
        )
        
        if not paper_ids:
            print("âŒ æœªæ‰¾åˆ°CSå€™é€‰æ± ")
            return
        
        test_paper_ids = paper_ids[:5]
        print(f"âœ… é€‰æ‹©5ç¯‡è®ºæ–‡æµ‹è¯•")
        
        # 2. ç”Ÿæˆç¿»è¯‘
        print("\nğŸŒ ç”Ÿæˆç¿»è¯‘...")
        translation_count = translate_and_save_papers(
            session=db,
            paper_ids=test_paper_ids,
            max_workers=2,
            force_retranslate=False
        )
        print(f"âœ… ç¿»è¯‘: {translation_count}/5 ç¯‡")
        
        # 3. ç”ŸæˆAIè§£è¯»
        print("\nğŸ¤– ç”ŸæˆAIè§£è¯»...")
        interpretation_results = batch_generate_interpretations(
            session=db,
            paper_ids=test_paper_ids,
            max_workers=2,
            force_regenerate=True  # å¼ºåˆ¶é‡æ–°ç”Ÿæˆ
        )
        print(f"âœ… AIè§£è¯»ç”Ÿæˆ: {len(interpretation_results)}/5 ç¯‡")
        
        # 4. ä¿å­˜AIè§£è¯»åˆ°æ•°æ®åº“
        if interpretation_results:
            print("\nğŸ’¾ ä¿å­˜AIè§£è¯»åˆ°æ•°æ®åº“...")
            saved_count = save_interpretations_to_db(db, interpretation_results)
            print(f"âœ… AIè§£è¯»ä¿å­˜: {saved_count}/5 ç¯‡")
        
        # 5. éªŒè¯æ•°æ®å®Œæ•´æ€§
        print("\nğŸ” éªŒè¯æ•°æ®å®Œæ•´æ€§...")
        query = text("""
            SELECT 
                p.id,
                p.title,
                COALESCE(pt.title_zh, p.title) as title_zh,
                pi.interpretation
            FROM papers p
            LEFT JOIN paper_translations pt ON p.id = pt.paper_id
            LEFT JOIN paper_interpretations pi ON p.id = pi.paper_id
            WHERE p.id = ANY(:paper_ids)
            AND pt.title_zh IS NOT NULL
            AND pi.interpretation IS NOT NULL
        """)
        
        result = db.execute(query, {"paper_ids": test_paper_ids})
        papers_data = result.fetchall()
        
        print(f"å®Œæ•´æ•°æ®çš„è®ºæ–‡: {len(papers_data)}/5")
        
        if not papers_data:
            print("âŒ æ•°æ®éªŒè¯å¤±è´¥")
            return
        
        # 6. ç”ŸæˆTTS
        print("\nğŸ”Š ç”ŸæˆTTSè¯­éŸ³...")
        
        async def generate_all_tts():
            tts_results = {}
            for paper_data in papers_data:
                paper_id, title_en, title_zh, interpretation = paper_data
                
                # ç»„åˆå†…å®¹
                clean_interpretation = clean_markdown_for_tts(interpretation)
                content = f"""
è®ºæ–‡æ ‡é¢˜ï¼š{title_zh}

è‹±æ–‡æ ‡é¢˜ï¼š{title_en}

AIè§£è¯»ï¼š{clean_interpretation}
                """.strip()
                
                print(f"  æ­£åœ¨ç”Ÿæˆ: {title_zh[:30]}...")
                
                try:
                    audio_bytes = await generate_single_tts_async(content)
                    tts_results[paper_id] = audio_bytes
                    print(f"  âœ“ å®Œæˆ: {len(audio_bytes)} å­—èŠ‚")
                except Exception as e:
                    print(f"  âœ— å¤±è´¥: {e}")
            
            return tts_results
        
        # è¿è¡Œå¼‚æ­¥TTSç”Ÿæˆ
        tts_results = asyncio.run(generate_all_tts())
        print(f"âœ… TTS: {len(tts_results)}/5 ç¯‡")
        
        # 7. ä¿å­˜TTSæ–‡ä»¶
        print("\nğŸ’¾ ä¿å­˜TTSæ–‡ä»¶...")
        output_dir = Path("data/tts")
        output_dir.mkdir(exist_ok=True, parents=True)
        
        saved_count = 0
        for paper_id, audio_bytes in tts_results.items():
            output_file = output_dir / f"{paper_id}.wav"
            output_file.write_bytes(audio_bytes)
            print(f"  âœ“ {output_file.name} ({len(audio_bytes)} å­—èŠ‚)")
            saved_count += 1
        
        # 8. æœ€ç»ˆæŠ¥å‘Š
        print(f"\nğŸ“Š æœ€ç»ˆæµ‹è¯•ç»“æœ:")
        print(f"ç¿»è¯‘æˆåŠŸ: {translation_count}/5")
        print(f"AIè§£è¯»æˆåŠŸ: {len(interpretation_results)}/5")
        print(f"æ•°æ®å®Œæ•´æ€§: {len(papers_data)}/5")
        print(f"TTSç”ŸæˆæˆåŠŸ: {len(tts_results)}/5")
        print(f"æ–‡ä»¶ä¿å­˜æˆåŠŸ: {saved_count}/5")
        
        success_rate = (saved_count / 5) * 100
        print(f"æ•´ä½“æˆåŠŸç‡: {success_rate:.1f}%")
        
        if success_rate == 100:
            print("\nğŸ‰ å®Œç¾ï¼æ‰€æœ‰5ç¯‡è®ºæ–‡çš„å®Œæ•´å†…å®¹ç”Ÿæˆæµç¨‹å…¨éƒ¨æˆåŠŸï¼")
            print("âœ… ç¿»è¯‘ â†’ AIè§£è¯» â†’ TTSè¯­éŸ³ å…¨æµç¨‹æµ‹è¯•é€šè¿‡")
        elif success_rate >= 80:
            print(f"\nâœ… ä¼˜ç§€ï¼{success_rate:.1f}%çš„è®ºæ–‡å®Œæˆäº†å®Œæ•´æµç¨‹")
        elif success_rate >= 60:
            print(f"\nâš ï¸  è‰¯å¥½ï¼{success_rate:.1f}%çš„è®ºæ–‡å®Œæˆäº†å®Œæ•´æµç¨‹")
        else:
            print(f"\nâŒ éœ€è¦æ”¹è¿›ï¼æˆåŠŸç‡ä»…{success_rate:.1f}%")
        
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¼‚å¸¸: {e}")
        db.rollback()
        raise
    finally:
        db.close()


if __name__ == "__main__":
    main()
