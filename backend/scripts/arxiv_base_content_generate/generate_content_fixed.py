#!/usr/bin/env python3
"""
ä¿®å¤ç‰ˆå†…å®¹ç”Ÿæˆè„šæœ¬

è§£å†³TTSç”Ÿæˆä¸­çš„æŸ¥è¯¢é—®é¢˜
"""
import os
import sys
from pathlib import Path

# ç¦ç”¨ä»£ç†
os.environ.pop('http_proxy', None)
os.environ.pop('https_proxy', None)
os.environ.pop('HTTP_PROXY', None)
os.environ.pop('HTTPS_PROXY', None)
os.environ.pop('all_proxy', None)
os.environ.pop('ALL_PROXY', None)

# æ·»åŠ backendæ ¹ç›®å½•åˆ°è·¯å¾„
backend_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(backend_root))

import pendulum
from sqlalchemy.orm import Session
from sqlalchemy import text
from app.db.session import SessionLocal
from app.services.data_ingestion.arxiv_candidate_pool import CandidatePoolServiceV2
from app.services.content_generation.translation_generate import translate_and_save_papers
from app.services.content_generation.ai_interpretation_generate import batch_generate_interpretations
from app.services.content_generation.tts_generate import clean_markdown_for_tts
import asyncio
import edge_tts


async def generate_single_tts_async(content: str, voice: str = "zh-CN-XiaoxiaoNeural") -> bytes:
    """å¼‚æ­¥ç”Ÿæˆå•ç¯‡TTS"""
    communicate = edge_tts.Communicate(content, voice)
    audio_bytes = b""
    
    async for chunk in communicate.stream():
        if chunk["type"] == "audio":
            audio_bytes += chunk["data"]
    
    return audio_bytes


def main():
    print("=== ä¿®å¤ç‰ˆå†…å®¹ç”Ÿæˆæµ‹è¯• ===")
    
    target_date = (pendulum.today() - pendulum.duration(days=3)).date()
    print(f"ä½¿ç”¨æ—¥æœŸ: {target_date}")
    
    db = SessionLocal()
    
    try:
        # 1. è·å–CSå€™é€‰æ± è®ºæ–‡
        print("\nğŸ“‹ è·å–CSå€™é€‰æ± è®ºæ–‡...")
        paper_ids = CandidatePoolServiceV2.get_candidate_papers_by_date(
            session=db,
            target_date=target_date,
            filter_type='cs'
        )
        
        if not paper_ids:
            print("âŒ æœªæ‰¾åˆ°CSå€™é€‰æ± ")
            return
        
        test_paper_ids = paper_ids[:5]
        print(f"âœ… é€‰æ‹©5ç¯‡è®ºæ–‡æµ‹è¯•")
        
        # 2. ç”Ÿæˆç¿»è¯‘
        print("\nğŸŒ ç”Ÿæˆç¿»è¯‘...")
        translation_count = translate_and_save_papers(
            session=db,
            paper_ids=test_paper_ids,
            max_workers=2,
            force_retranslate=False
        )
        print(f"âœ… ç¿»è¯‘: {translation_count}/5 ç¯‡")
        
        # 3. ç”ŸæˆAIè§£è¯»
        print("\nğŸ¤– ç”ŸæˆAIè§£è¯»...")
        interpretation_results = batch_generate_interpretations(
            session=db,
            paper_ids=test_paper_ids,
            max_workers=2,
            force_regenerate=False
        )
        print(f"âœ… AIè§£è¯»: {len(interpretation_results)}/5 ç¯‡")
        
        # 4. æ‰‹åŠ¨æŸ¥è¯¢è®ºæ–‡æ•°æ®å¹¶ç”ŸæˆTTS
        print("\nğŸ”Š ç”ŸæˆTTSè¯­éŸ³...")
        
        # ç›´æ¥æŸ¥è¯¢æ•°æ®åº“è·å–å®Œæ•´æ•°æ®
        query = text("""
            SELECT 
                p.id,
                p.title,
                COALESCE(pt.title_zh, p.title) as title_zh,
                pi.interpretation
            FROM papers p
            LEFT JOIN paper_translations pt ON p.id = pt.paper_id
            LEFT JOIN paper_interpretations pi ON p.id = pi.paper_id
            WHERE p.id = ANY(:paper_ids)
            AND pt.title_zh IS NOT NULL
            AND pi.interpretation IS NOT NULL
        """)
        
        result = db.execute(query, {"paper_ids": test_paper_ids})
        papers_data = result.fetchall()
        
        print(f"æ‰¾åˆ°å®Œæ•´æ•°æ®çš„è®ºæ–‡: {len(papers_data)}/5")
        
        if not papers_data:
            print("âŒ æœªæ‰¾åˆ°åŒ…å«ç¿»è¯‘å’Œè§£è¯»çš„è®ºæ–‡æ•°æ®")
            return
        
        # å¼‚æ­¥ç”ŸæˆTTS
        async def generate_all_tts():
            tts_results = {}
            for paper_data in papers_data:
                paper_id, title_en, title_zh, interpretation = paper_data
                
                # ç»„åˆå†…å®¹
                clean_interpretation = clean_markdown_for_tts(interpretation)
                content = f"""
è®ºæ–‡æ ‡é¢˜ï¼š{title_zh}

è‹±æ–‡æ ‡é¢˜ï¼š{title_en}

AIè§£è¯»ï¼š{clean_interpretation}
                """.strip()
                
                print(f"  æ­£åœ¨ç”Ÿæˆ: {title_zh[:30]}...")
                
                try:
                    audio_bytes = await generate_single_tts_async(content)
                    tts_results[paper_id] = audio_bytes
                    print(f"  âœ“ å®Œæˆ: {len(audio_bytes)} å­—èŠ‚")
                except Exception as e:
                    print(f"  âœ— å¤±è´¥: {e}")
            
            return tts_results
        
        # è¿è¡Œå¼‚æ­¥TTSç”Ÿæˆ
        tts_results = asyncio.run(generate_all_tts())
        
        print(f"âœ… TTS: {len(tts_results)}/5 ç¯‡")
        
        # 5. ä¿å­˜TTSæ–‡ä»¶
        print("\nğŸ’¾ ä¿å­˜TTSæ–‡ä»¶...")
        output_dir = Path("data/tts")
        output_dir.mkdir(exist_ok=True, parents=True)
        
        saved_count = 0
        for paper_id, audio_bytes in tts_results.items():
            output_file = output_dir / f"{paper_id}.wav"
            output_file.write_bytes(audio_bytes)
            print(f"  âœ“ {output_file.name} ({len(audio_bytes)} å­—èŠ‚)")
            saved_count += 1
        
        # 6. æµ‹è¯•æ€»ç»“
        print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
        print(f"ç¿»è¯‘æˆåŠŸ: {translation_count}/5")
        print(f"AIè§£è¯»æˆåŠŸ: {len(interpretation_results)}/5")
        print(f"TTSç”ŸæˆæˆåŠŸ: {len(tts_results)}/5")
        print(f"æ–‡ä»¶ä¿å­˜æˆåŠŸ: {saved_count}/5")
        
        complete_count = len([p for p in papers_data if p[0] in tts_results])
        print(f"å®Œæ•´æµç¨‹æˆåŠŸ: {complete_count}/5")
        
        if complete_count == 5:
            print("\nğŸ‰ å®Œç¾ï¼æ‰€æœ‰5ç¯‡è®ºæ–‡çš„å†…å®¹ç”Ÿæˆæµç¨‹å…¨éƒ¨æˆåŠŸï¼")
        elif complete_count > 0:
            print(f"\nâœ… éƒ¨åˆ†æˆåŠŸï¼{complete_count}ç¯‡è®ºæ–‡å®Œæˆäº†å®Œæ•´æµç¨‹")
        else:
            print("\nâŒ æµç¨‹å¤±è´¥ï¼Œè¯·æ£€æŸ¥æœåŠ¡é…ç½®")
        
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¼‚å¸¸: {e}")
        db.rollback()
        raise
    finally:
        db.close()


if __name__ == "__main__":
    main()
