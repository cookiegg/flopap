#!/usr/bin/env python3
"""
arXivåŸºç¡€å†…å®¹ç”Ÿæˆæµ‹è¯•è„šæœ¬

å®Œæ•´æµç¨‹ï¼šCSå€™é€‰æ±  â†’ ç¿»è¯‘ â†’ AIè§£è¯» â†’ TTSè¯­éŸ³
"""
import os
import sys
import subprocess
from pathlib import Path
from uuid import UUID

# ç¦ç”¨ä»£ç†
os.environ.pop('http_proxy', None)
os.environ.pop('https_proxy', None)
os.environ.pop('HTTP_PROXY', None)
os.environ.pop('HTTPS_PROXY', None)
os.environ.pop('all_proxy', None)
os.environ.pop('ALL_PROXY', None)

# æ·»åŠ backendæ ¹ç›®å½•åˆ°è·¯å¾„
backend_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(backend_root))

import pendulum
from sqlalchemy.orm import Session
from app.db.session import SessionLocal
from app.services.data_ingestion.arxiv_candidate_pool import CandidatePoolServiceV2
from app.services.content_generation.translation_generate import translate_and_save_papers
from app.services.content_generation.ai_interpretation_generate import batch_generate_interpretations
from app.services.content_generation.tts_generate import batch_generate_tts
from app.services.tts_storage import tts_storage


def main():
    print("=== arXivåŸºç¡€å†…å®¹ç”Ÿæˆæµ‹è¯• ===")
    
    # 1. ç”ŸæˆCSå€™é€‰æ± 
    print("\nğŸ”„ æ­¥éª¤1: ç”ŸæˆCSå€™é€‰æ± ...")
    target_date = (pendulum.today() - pendulum.duration(days=3)).date()
    print(f"ç›®æ ‡æ—¥æœŸ: {target_date}")
    
    try:
        result = subprocess.run([
            sys.executable, 
            "scripts/arxiv_candidate_pool/generate_cs_pool.py",
            "--days-ago", "3"
        ], cwd=backend_root, capture_output=True, text=True)
        
        if result.returncode != 0:
            print(f"âŒ CSå€™é€‰æ± ç”Ÿæˆå¤±è´¥: {result.stderr}")
            return
        
        print("âœ… CSå€™é€‰æ± ç”Ÿæˆå®Œæˆ")
    except Exception as e:
        print(f"âŒ CSå€™é€‰æ± ç”Ÿæˆå¼‚å¸¸: {e}")
        return
    
    # 2. è·å–å€™é€‰æ± ä¸­çš„è®ºæ–‡
    print("\nğŸ”„ æ­¥éª¤2: è·å–å€™é€‰æ± è®ºæ–‡...")
    db = SessionLocal()
    
    try:
        paper_ids = CandidatePoolServiceV2.get_candidate_papers_by_date(
            session=db,
            target_date=target_date,
            filter_type='cs'
        )
        
        if not paper_ids:
            print("âŒ æœªæ‰¾åˆ°CSå€™é€‰æ± è®ºæ–‡")
            return
        
        # å–å‰5ç¯‡è¿›è¡Œæµ‹è¯•
        test_paper_ids = paper_ids[:5]
        print(f"âœ… è·å–åˆ° {len(paper_ids)} ç¯‡CSè®ºæ–‡ï¼Œé€‰æ‹©å‰5ç¯‡æµ‹è¯•")
        print(f"æµ‹è¯•è®ºæ–‡ID: {[str(pid)[:8] + '...' for pid in test_paper_ids]}")
        
        # 3. ç”Ÿæˆç¿»è¯‘
        print("\nğŸ”„ æ­¥éª¤3: ç”Ÿæˆç¿»è¯‘...")
        translation_count = translate_and_save_papers(
            session=db,
            paper_ids=test_paper_ids,
            max_workers=3,
            force_retranslate=False
        )
        print(f"âœ… ç¿»è¯‘å®Œæˆ: {translation_count} ç¯‡")
        
        # 4. ç”ŸæˆAIè§£è¯»
        print("\nğŸ”„ æ­¥éª¤4: ç”ŸæˆAIè§£è¯»...")
        interpretation_results = batch_generate_interpretations(
            session=db,
            paper_ids=test_paper_ids,
            max_workers=3,
            force_regenerate=False
        )
        print(f"âœ… AIè§£è¯»å®Œæˆ: {len(interpretation_results)} ç¯‡")
        
        # 5. ç”ŸæˆTTSè¯­éŸ³
        print("\nğŸ”„ æ­¥éª¤5: ç”ŸæˆTTSè¯­éŸ³...")
        tts_results = batch_generate_tts(
            session=db,
            paper_ids=test_paper_ids,
            voice="zh-CN-XiaoxiaoNeural",
            max_workers=3
        )
        print(f"âœ… TTSç”Ÿæˆå®Œæˆ: {len(tts_results)} ç¯‡")
        
        # 6. ä¿å­˜TTSåˆ°å­˜å‚¨ç³»ç»Ÿ
        print("\nğŸ”„ æ­¥éª¤6: ä¿å­˜TTSæ–‡ä»¶...")
        saved_count = 0
        for paper_id, audio_bytes in tts_results.items():
            # è·å–è®ºæ–‡å†…å®¹ç”¨äºå­˜å‚¨
            from app.services.content_generation.tts_generate import get_papers_with_content, clean_markdown_for_tts
            papers_data = get_papers_with_content(db, [paper_id])
            
            if papers_data:
                paper_data = papers_data[0]
                _, title_en, title_zh, interpretation = paper_data
                content = f"è®ºæ–‡æ ‡é¢˜ï¼š{title_zh}\nè‹±æ–‡æ ‡é¢˜ï¼š{title_en}\nAIè§£è¯»ï¼š{clean_markdown_for_tts(interpretation)}"
                
                tts_record = tts_storage.save_tts_file(
                    session=db,
                    paper_id=paper_id,
                    audio_bytes=audio_bytes,
                    voice_model="zh-CN-XiaoxiaoNeural",
                    content=content
                )
                
                if tts_record:
                    saved_count += 1
                    file_path = tts_storage.base_dir / tts_record.file_path
                    print(f"  âœ“ {paper_id}: {file_path}")
        
        print(f"âœ… TTSæ–‡ä»¶ä¿å­˜å®Œæˆ: {saved_count} ä¸ªæ–‡ä»¶")
        
        # 7. ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        print("\nğŸ“Š æµ‹è¯•æŠ¥å‘Š:")
        print(f"ç›®æ ‡æ—¥æœŸ: {target_date}")
        print(f"CSå€™é€‰æ± è®ºæ–‡æ•°: {len(paper_ids)}")
        print(f"æµ‹è¯•è®ºæ–‡æ•°: {len(test_paper_ids)}")
        print(f"ç¿»è¯‘æˆåŠŸ: {translation_count} ç¯‡")
        print(f"AIè§£è¯»æˆåŠŸ: {len(interpretation_results)} ç¯‡")
        print(f"TTSç”ŸæˆæˆåŠŸ: {len(tts_results)} ç¯‡")
        print(f"TTSæ–‡ä»¶ä¿å­˜: {saved_count} ä¸ª")
        
        success_rate = (saved_count / len(test_paper_ids)) * 100
        print(f"æ•´ä½“æˆåŠŸç‡: {success_rate:.1f}%")
        
        if success_rate == 100:
            print("\nğŸ‰ æ‰€æœ‰æ­¥éª¤å®Œæˆï¼å†…å®¹ç”Ÿæˆæµæ°´çº¿æµ‹è¯•æˆåŠŸï¼")
        else:
            print(f"\nâš ï¸  éƒ¨åˆ†æ­¥éª¤å¤±è´¥ï¼ŒæˆåŠŸç‡: {success_rate:.1f}%")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹å¼‚å¸¸: {e}")
        db.rollback()
        raise
    finally:
        db.close()


if __name__ == "__main__":
    main()
