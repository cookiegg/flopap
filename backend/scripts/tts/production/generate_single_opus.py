#!/usr/bin/env python3
"""
AIè§£è¯»TTSç”Ÿæˆè„šæœ¬ - å•ä¸ªOPUSæ–‡ä»¶ï¼Œä½ç ç‡ä¼˜åŒ–
"""

import asyncio
import argparse
import subprocess
import re
import sys
from pathlib import Path
from uuid import UUID

backend_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(backend_root))

import edge_tts
from sqlalchemy import text
from app.db.session import SessionLocal

def clean_markdown_for_tts(text: str) -> str:
    """æ¸…ç†markdownè¯­æ³•ï¼Œä¼˜åŒ–TTSæœ—è¯»"""
    if not text:
        return text
    
    # å¤„ç†JSONæ ¼å¼çš„è§£è¯»å†…å®¹
    if text.strip().startswith('```json'):
        try:
            import json
            json_match = re.search(r'```json\s*(\[.*?\])\s*```', text, re.DOTALL)
            if json_match:
                json_data = json.loads(json_match.group(1))
                content_parts = []
                for item in json_data:
                    if isinstance(item, dict) and 'zh' in item:
                        content_parts.append(item['zh'])
                text = '\n\n'.join(content_parts)
        except:
            pass
    
    # æ¸…ç†markdownè¯­æ³•
    text = re.sub(r'```[^`]*```', '', text)
    text = re.sub(r'`([^`]+)`', r'\1', text)
    text = re.sub(r'\*\*([^*]+)\*\*', r'\1', text)
    text = re.sub(r'\*([^*]+)\*', r'\1', text)
    text = re.sub(r'#{1,6}\s*', '', text)
    text = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', text)
    text = re.sub(r'^\s*[-*+]\s+', '', text, flags=re.MULTILINE)
    text = re.sub(r'^\s*\d+\.\s+', '', text, flags=re.MULTILINE)
    text = re.sub(r'\n{3,}', '\n\n', text)
    
    return text.strip()

async def generate_single_tts(paper_id: str, content: str, voice: str, output_path: Path):
    """ç”Ÿæˆå•ä¸ªTTSæ–‡ä»¶"""
    try:
        # æ¸…ç†å†…å®¹
        clean_content = clean_markdown_for_tts(content)
        
        if len(clean_content) < 10:
            print(f"âŒ å†…å®¹è¿‡çŸ­: {paper_id}")
            return False
        
        # ç”ŸæˆTTS
        communicate = edge_tts.Communicate(clean_content, voice)
        
        # ä¸´æ—¶WAVæ–‡ä»¶
        temp_wav = output_path.with_suffix('.wav')
        
        # ä¿å­˜ä¸ºWAV
        await communicate.save(str(temp_wav))
        
        # è½¬æ¢ä¸ºä½ç ç‡OPUS
        cmd = [
            'ffmpeg', '-i', str(temp_wav),
            '-c:a', 'libopus',
            '-b:a', '24k',  # 24kbpsç ç‡
            '-vbr', 'on',   # å¯å˜æ¯”ç‰¹ç‡
            '-compression_level', '10',  # æœ€é«˜å‹ç¼©
            '-frame_duration', '60',     # 60mså¸§é•¿åº¦
            '-y',  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
            str(output_path)
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode != 0:
            print(f"âŒ FFmpegè½¬æ¢å¤±è´¥: {paper_id}")
            print(f"   é”™è¯¯: {result.stderr}")
            return False
        
        # åˆ é™¤ä¸´æ—¶WAVæ–‡ä»¶
        temp_wav.unlink(missing_ok=True)
        
        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
        if output_path.exists() and output_path.stat().st_size > 1000:
            file_size = output_path.stat().st_size / 1024
            print(f"âœ… {paper_id}: {file_size:.1f}KB")
            return True
        else:
            print(f"âŒ è¾“å‡ºæ–‡ä»¶å¼‚å¸¸: {paper_id}")
            return False
            
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå¤±è´¥ {paper_id}: {e}")
        return False

async def process_papers(source_filter: str, voice: str, output_dir: Path, concurrency: int):
    """æ‰¹é‡å¤„ç†è®ºæ–‡"""
    
    # æŸ¥è¯¢è®ºæ–‡
    db = SessionLocal()
    try:
        query = """
        SELECT pi.paper_id, pi.interpretation
        FROM paper_interpretations pi
        JOIN papers p ON pi.paper_id = p.id
        WHERE pi.interpretation IS NOT NULL 
        AND LENGTH(pi.interpretation) > 50
        """
        
        params = {}
        if source_filter:
            query += " AND p.source = :source"
            params['source'] = source_filter
        
        query += " ORDER BY pi.paper_id"
        
        result = db.execute(text(query), params)
        papers = result.fetchall()
        
    finally:
        db.close()
    
    if not papers:
        print("âŒ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è®ºæ–‡")
        return
    
    print(f"ğŸ“š æ‰¾åˆ° {len(papers)} ç¯‡è®ºæ–‡")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir.mkdir(exist_ok=True, parents=True)
    
    # å¹¶å‘æ§åˆ¶
    semaphore = asyncio.Semaphore(concurrency)
    
    async def process_single_paper(paper_id, content):
        async with semaphore:
            output_file = output_dir / f"{paper_id}.opus"
            
            # è·³è¿‡å·²å­˜åœ¨çš„æ–‡ä»¶
            if output_file.exists():
                print(f"â­ï¸  è·³è¿‡å·²å­˜åœ¨: {paper_id}")
                return True
            
            return await generate_single_tts(paper_id, content, voice, output_file)
    
    # æ‰¹é‡å¤„ç†
    tasks = [process_single_paper(str(paper[0]), paper[1]) for paper in papers]
    
    print(f"ğŸš€ å¼€å§‹æ‰¹é‡ç”Ÿæˆ (å¹¶å‘æ•°: {concurrency})...")
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # ç»Ÿè®¡ç»“æœ
    success_count = sum(1 for r in results if r is True)
    total_count = len(results)
    
    print(f"\nğŸ“Š ç”Ÿæˆå®Œæˆ!")
    print(f"âœ… æˆåŠŸ: {success_count}/{total_count} ({success_count/total_count*100:.1f}%)")
    
    # è®¡ç®—æ€»å¤§å°
    total_size = sum(f.stat().st_size for f in output_dir.glob("*.opus"))
    print(f"ğŸ’¾ æ€»å¤§å°: {total_size/1024/1024:.1f} MB")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")

async def main():
    parser = argparse.ArgumentParser(description="AIè§£è¯»TTSç”Ÿæˆ - å•æ–‡ä»¶ä½ç ç‡ç‰ˆæœ¬")
    parser.add_argument("--source", help="è®ºæ–‡æ¥æºè¿‡æ»¤ (å¦‚: conf/iclr2024)")
    parser.add_argument("--voice", default="zh-CN-XiaoxiaoNeural", help="è¯­éŸ³æ¨¡å‹")
    parser.add_argument("--output-dir", default="/data/proj/flopap/data/tts_opus", help="è¾“å‡ºç›®å½•")
    parser.add_argument("--concurrency", type=int, default=6, help="å¹¶å‘æ•°")
    
    args = parser.parse_args()
    
    print("ğŸµ AIè§£è¯»TTSç”Ÿæˆå™¨ - å•æ–‡ä»¶ä½ç ç‡ç‰ˆæœ¬")
    print(f"ğŸ“š è®ºæ–‡æ¥æº: {args.source or 'å…¨éƒ¨'}")
    print(f"ğŸ¤ è¯­éŸ³æ¨¡å‹: {args.voice}")
    print(f"âš¡ å¹¶å‘æ•°: {args.concurrency}")
    print(f"ğŸ›ï¸  ç ç‡è®¾ç½®: 24kbps VBR")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
    print("-" * 50)
    
    output_dir = Path(args.output_dir)
    
    await process_papers(args.source, args.voice, output_dir, args.concurrency)

if __name__ == "__main__":
    asyncio.run(main())
