#!/usr/bin/env python3
"""
ä¿®å¤ä¸å®Œæ•´è®ºæ–‡çš„TTSæ–‡ä»¶
"""

import asyncio
import argparse
from pathlib import Path
from uuid import UUID
import sys

# å¤ç”¨final_fix.pyçš„æ ¸å¿ƒé€»è¾‘
backend_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(backend_root))

from sqlalchemy import text
from app.db.session import SessionLocal

# å¯¼å…¥ç”Ÿæˆå‡½æ•°
from generate_batch_tts_optimized import segment_interpretation, generate_segment_tts


async def main():
    parser = argparse.ArgumentParser(description="ä¿®å¤ä¸å®Œæ•´çš„TTSæ–‡ä»¶")
    parser.add_argument("--source", help="è®ºæ–‡æ¥æºè¿‡æ»¤ (å¯é€‰)")
    parser.add_argument("--voice", default="zh-CN-XiaoxiaoNeural", help="è¯­éŸ³æ¨¡å‹")
    parser.add_argument("--output-dir", default="backend/data/tts", help="TTSç›®å½•")
    
    args = parser.parse_args()
    
    print("ğŸ”§ ä¿®å¤ä¸å®Œæ•´çš„TTSæ–‡ä»¶")
    
    tts_dir = Path(args.output_dir)
    
    # æ‰¾å‡ºä¸å®Œæ•´çš„è®ºæ–‡
    incomplete_papers = []
    
    for paper_dir in tts_dir.iterdir():
        if not paper_dir.is_dir():
            continue
        
        try:
            paper_id = UUID(paper_dir.name)
        except ValueError:
            continue
        
        opus_files = list(paper_dir.glob('*.opus'))
        if len(opus_files) < 6:
            missing_segments = []
            for i in range(6):
                opus_file = paper_dir / f"segment_{i:02d}_part_{i+1}.opus"
                if not opus_file.exists():
                    missing_segments.append(i)
            
            if missing_segments:
                incomplete_papers.append((paper_id, missing_segments))
    
    print(f"ğŸ“Š å‘ç° {len(incomplete_papers)} ç¯‡ä¸å®Œæ•´è®ºæ–‡")
    
    if not incomplete_papers:
        print("âœ… æ‰€æœ‰è®ºæ–‡éƒ½å·²å®Œæ•´")
        return
    
    # æ‰¹é‡è·å–è®ºæ–‡æ•°æ®
    db = SessionLocal()
    paper_data = {}
    
    try:
        paper_ids = [str(pid) for pid, _ in incomplete_papers]
        
        where_clause = "p.id = ANY(:paper_ids)"
        params = {"paper_ids": paper_ids}
        
        if args.source:
            where_clause += " AND p.source = :source"
            params["source"] = args.source
        
        query_sql = text(f"""
            SELECT 
                p.id,
                p.title,
                COALESCE(pt.title_zh, p.title) as title_zh,
                pi.interpretation
            FROM papers p
            LEFT JOIN paper_translations pt ON p.id = pt.paper_id
            LEFT JOIN paper_interpretations pi ON p.id = pi.paper_id
            WHERE {where_clause}
            AND pi.interpretation IS NOT NULL
        """)
        
        result = db.execute(query_sql, params)
        
        for row in result:
            paper_data[row.id] = {
                'title_en': row.title,
                'title_zh': row.title_zh,
                'interpretation': row.interpretation
            }
    
    finally:
        db.close()
    
    # ç”Ÿæˆç¼ºå¤±ç‰‡æ®µ
    total_generated = 0
    
    for i, (paper_id, missing_segments) in enumerate(incomplete_papers):
        if paper_id not in paper_data:
            print(f"âŒ è®ºæ–‡ {paper_id} æ²¡æœ‰AIè§£è¯»")
            continue
        
        data = paper_data[paper_id]
        print(f"\nğŸµ [{i+1}/{len(incomplete_papers)}] ä¿®å¤: {paper_id} (ç¼ºå¤± {len(missing_segments)} ä¸ªç‰‡æ®µ)")
        
        # å‡†å¤‡å†…å®¹å¹¶åˆ†æ®µ
        full_content = f"è®ºæ–‡æ ‡é¢˜ï¼š{data['title_zh']}\nè‹±æ–‡æ ‡é¢˜ï¼š{data['title_en']}\nAIè§£è¯»ï¼š{data['interpretation']}"
        segments = segment_interpretation(full_content, target_segments=6)
        
        paper_dir = tts_dir / str(paper_id)
        
        # ç”Ÿæˆç¼ºå¤±ç‰‡æ®µ
        for segment_idx in missing_segments:
            if segment_idx < len(segments):
                segment_type, segment_text = segments[segment_idx]
                segment_file = paper_dir / f"segment_{segment_idx:02d}_{segment_type}.opus"
                
                print(f"  ğŸ”„ ç‰‡æ®µ {segment_idx+1} ({len(segment_text)} å­—ç¬¦)")
                
                if await generate_segment_tts(segment_text, segment_file, args.voice):
                    total_generated += 1
                    print(f"    âœ… æˆåŠŸ")
                else:
                    print(f"    âŒ å¤±è´¥")
    
    print(f"\nğŸ‰ ä¿®å¤å®Œæˆï¼ç”Ÿæˆäº† {total_generated} ä¸ªç‰‡æ®µ")


if __name__ == "__main__":
    asyncio.run(main())
