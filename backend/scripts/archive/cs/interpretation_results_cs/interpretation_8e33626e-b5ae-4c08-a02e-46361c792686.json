{
  "paper_id": "8e33626e-b5ae-4c08-a02e-46361c792686",
  "arxiv_id": "2512.12177v1",
  "title": "Floorplan2Guide: LLM-Guided Floorplan Parsing for BLV Indoor Navigation",
  "ai_interpretation": "这篇论文旨在解决**视障人士室内导航**的难题。传统方案依赖蓝牙信标等基础设施，成本高且难以适应动态环境。本文提出了一种**低成本、无需额外硬件**的创新思路：利用现有建筑平面图，通过大语言模型自动解析，生成导航指令。\n\n**核心创新点**在于：\n1.  **LLM驱动的平面图解析**：首次将大语言模型用于自动提取平面图中的房间、门、走廊等空间关系，大幅减少了传统方法所需的人工预处理。\n2.  **知识图谱构建**：将解析出的信息构建成结构化的**导航知识图谱**，明确表达空间连接性，比直接让模型“看图说话”更可靠。\n3.  **上下文学习优化**：采用**少量示例学习**，仅需提供5个示例，就能显著提升LLM的理解和导航指令生成精度。\n\n**技术流程**分为三步：\n- **解析**：LLM分析平面图的文本描述（如SVG代码），识别空间实体及其关系。\n- **建图**：将解析结果构建成知识图谱，作为导航的“数字地图”。\n- **导航**：根据用户起点和终点，在图上规划路径，并由LLM生成一步步的**自然语言导航指令**。\n\n**实验结果**非常有力：\n- 在模拟和真实场景测试中，**5示例学习**的效果全面优于零示例学习。\n- **Claude 3.7 Sonnet**模型表现最佳，在短、中、长路径规划上的准确率分别达到92.31%、76.92%和61.54%。\n- 关键发现：**基于知识图谱的方法**比让LLM直接进行视觉推理的成功率高出15.4%，证明了结构化空间表征的巨大优势。\n\n**学术价值**在于：\n- 为**具身AI**和**无障碍技术**提供了新颖的交叉研究范式。\n- 证明了**基础模型**在复杂空间认知任务上的潜力，以及**上下文学习**对提升精度的有效性。\n- 提出了一套可复现的框架，将非结构化的平面图转化为可计算、可推理的知识图谱。\n\n**未来方向**包括：\n- 处理更复杂的多层建筑和动态障碍物。\n- 集成实时感知（如手机传感器）进行定位与纠偏。\n- 探索多模态模型直接处理原始平面图图像，进一步简化流程。\n\n总之，这项工作巧妙利用LLM的推理能力，将普通的建筑平面图转化为视障人士的“导航助手”，为实现普惠、低成本的室内导航提供了切实可行的技术路径。",
  "timestamp": "2025-12-16T22:33:00.799966",
  "model_name": "deepseek-reasoner"
}