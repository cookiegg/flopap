{
  "paper_id": "56cb6936-1c22-4f06-9554-579135cd969f",
  "arxiv_id": "2512.12284v1",
  "title": "V-Rex: Real-Time Streaming Video LLM Acceleration via Dynamic KV Cache Retrieval",
  "ai_interpretation": "这篇论文针对**流媒体视频大模型（LLM）在边缘设备上部署时面临的实时性难题**，提出了软硬件协同设计的创新解决方案V-Rex。\n\n### 1. 研究背景与动机\n流媒体视频LLM（如视频问答、实时字幕生成）需要连续处理视频帧。其核心瓶颈在于**KV缓存（Key-Value Cache）**：随着视频流持续输入，存储历史信息的KV缓存会急剧膨胀，导致：\n- **计算与内存负担沉重**：每次处理新帧都需“预填充”大量历史缓存，产生重复计算。\n- **边缘部署困难**：边缘设备算力、内存有限，难以承受上述开销，导致延迟高、能效差。\n\n### 2. 核心创新点与贡献\n- **算法层面**：提出**ReSV算法**，无需重新训练，通过**时空相似性聚类**动态检索和压缩KV缓存，大幅减少冗余。\n- **硬件层面**：设计专用加速器**DRE（动态KV缓存检索引擎）**，以极低的面积和功耗（仅占2%左右）高效执行ReSV算法。\n- **系统成果**：首次实现**边缘设备上实时流媒体视频LLM推理**（3.9-8.3 FPS），速度提升最高达19.7倍，能效提升最高达18.5倍，且精度损失可忽略。\n\n### 3. 技术方法详解\n- **ReSV算法**：将视频帧中的token（视觉特征单元）按时间和空间相似性聚类，仅保留代表性token的KV缓存，相似token直接复用，避免重复存储。\n- **DRE硬件引擎**：包含**比特级计算单元**（降低数据精度开销）和**提前退出机制**（满足条件即停止计算），轻量化实现高效检索。\n\n### 4. 实验结果分析\n在Jetson AGX Orin等边缘平台测试显示：\n- 在多种视频任务（如Video-ChatGPT）上保持高精度（准确率下降<1%）。\n- 相比GPU基线，实现显著加速和能效提升，证明了软硬件协同设计的有效性。\n\n### 5. 学术价值与影响\n- **开辟新方向**：首次系统解决流媒体视频LLM的KV缓存爆炸问题，涵盖算法与硬件。\n- **推动边缘AI落地**：为实时视频分析、AR交互等应用提供了可行的边缘部署方案。\n- **方法论示范**：展示了软硬件协同设计在解决大模型部署瓶颈中的强大潜力。\n\n### 6. 未来研究方向\n- 将方法扩展至更多模态（如音频流）。\n- 探索与模型压缩、稀疏化技术的结合。\n- 研究动态聚类算法的自适应优化策略。\n\n**总结**：V-Rex通过“智能缓存检索算法+轻量专用硬件”的组合拳，精准击中了流媒体视频LLM的部署痛点，为边缘AI实时化提供了创新且高效的范例。",
  "timestamp": "2025-12-16T22:32:40.448486",
  "model_name": "deepseek-reasoner"
}