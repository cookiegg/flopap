{
  "paper_id": "b15c8a69-008e-42f9-9570-0489a3d1e0e3",
  "arxiv_id": "2512.12372v1",
  "title": "STAGE: Storyboard-Anchored Generation for Cinematic Multi-shot Narrative",
  "ai_interpretation": "这篇论文针对当前AI视频生成的痛点——**难以制作连贯、有电影感的“多镜头叙事”视频**，提出了一个名为 **STAGE** 的创新解决方案。\n\n### 1. 背景与动机\n现有视频生成模型虽能生成单段高清视频，但直接生成长篇、多场景（镜头切换）的故事时，往往出现角色/场景前后不一致、镜头语言混乱的问题。一种折中方案是先生成关键帧再补全，但传统关键帧过于稀疏，无法有效控制镜头起止和转场，导致叙事不连贯。\n\n### 2. 核心创新与贡献\n- **核心创新**：用**故事板**替代稀疏关键帧。故事板是电影工业的蓝图，明确规定了每个镜头的起止画面和衔接方式。\n- **三大贡献**：\n  - **STAGE工作流**：一个端到端的、以故事板为锚点的多镜头视频生成框架。\n  - **ConStoryBoard数据集**：包含高质量电影片段、精细标注（故事进展、电影属性、人类偏好）的大规模数据集。\n  - **STEP2模块**：能根据文本描述，预测出结构化的故事板（每个镜头由起止帧对定义）。\n\n### 3. 技术方法详解\nSTAGE的工作流程分为两步：\n- **第一步（故事板生成）**：利用STEP2模块，根据叙事文本生成一个包含多个镜头起止帧的**结构化故事板**。这为后续视频生成提供了精确的“施工图”。\n- **第二步（视频生成与补全）**：\n  - **多镜头记忆包**：存储并传递关键实体（如主角）信息，确保其在所有镜头中保持一致。\n  - **双重编码策略**：同时编码一个镜头的起止帧，保证单个镜头内部的连贯性。\n  - **两阶段训练**：先学习生成单个镜头，再专门学习镜头之间的**电影化转场**，使切换更自然、有艺术感。\n\n### 4. 实验结果分析\n论文在自建的ConStoryBoard数据集上进行了大量实验。结果表明，STAGE在以下方面显著优于现有方法：\n- **叙事结构控制**：能更准确地遵循预设的故事板结构。\n- **跨镜头一致性**：角色、物体等在多个镜头中保持稳定。\n- **电影语言质量**：生成的镜头转场更符合电影语法，视觉效果更专业。\n\n### 5. 学术价值与影响\n该研究将**电影工业的专业知识（故事板）** 系统性地引入AI视频生成领域，为解决多镜头叙事的核心难题提供了新范式。它强调了**结构化中间表示**的重要性，推动了该领域从追求“单段逼真”向“长篇连贯”的演进。开源的数据集也为后续研究提供了宝贵资源。\n\n### 6. 未来方向\n- 扩展至更复杂的叙事结构和更长的时间跨度。\n- 融入声音、对白等多元模态，实现真正的视听叙事。\n- 探索更动态、可交互的故事板生成与控制。\n\n**总结**：STAGE的核心思想是**“像导演一样思考”**——先规划好故事板蓝图，再基于蓝图生成高质量、连贯的多镜头视频，是迈向可控、专业级AI影视制作的重要一步。",
  "timestamp": "2025-12-16T22:32:19.298906",
  "model_name": "deepseek-reasoner"
}