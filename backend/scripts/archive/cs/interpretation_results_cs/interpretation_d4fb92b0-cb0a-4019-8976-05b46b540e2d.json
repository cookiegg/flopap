{
  "paper_id": "d4fb92b0-cb0a-4019-8976-05b46b540e2d",
  "arxiv_id": "2512.12348v1",
  "title": "Understanding Trust Toward Human versus AI-generated Health Information through Behavioral and Physiological Sensing",
  "ai_interpretation": "这篇论文探讨了一个关键问题：**当AI生成的健康信息充斥网络时，人们究竟如何信任它？** 研究通过行为与生理数据，揭示了“来源”与“标签”对信任的复杂影响。\n\n### 1. 背景与动机\nAI（如ChatGPT）生成的健康信息日益普遍，且质量足以“以假乱真”。但信息可能不准确，若用户盲目信任将带来风险。因此，理解人们如何判断和信任AI生成内容，对设计透明、安全的在线健康环境至关重要。\n\n### 2. 核心创新点\n- **双维度设计**：同时考察信息的**真实来源**（人/AI生成）和**展示标签**（标为“人写”/“AI写”），区分了客观事实与主观提示的影响。\n- **多模态感知**：结合传统问卷、眼动追踪和生理传感（心电、皮电、皮肤温度），从“主观报告”深入到“无意识行为与生理反应”。\n\n### 3. 技术方法\n- **研究1（问卷，142人）**：采用2×2×3实验设计，系统变换信息源、标签和健康主题（常识/症状/治疗），测量信任评分。\n- **研究2（实验室，40人）**：在呈现信息时，同步记录参与者的**眼动模式**（如注视时间、瞳孔变化）和**生理信号**，探究其与信任的内在关联。\n\n### 4. 实验结果\n- **信任悖论**：**AI生成的内容比人生成的更受信任**（可能因表述更流畅、结构化），但**贴上“人”标签的信息比“AI”标签更受信任**。这说明“透明标签”能有效调节信任，即使内容本身来自AI。\n- **类型无差异**：信任水平在不同健康主题间无显著变化。\n- **行为生理差异**：不同来源和标签的信息引发了显著不同的眼动模式和生理反应（如注意力分配、唤醒度）。\n- **预测模型**：利用眼动和生理特征训练机器学习模型，能以**73%的准确率预测**用户是否信任该信息，以**65%的准确率推断**信息真实来源。\n\n### 5. 学术价值与影响\n- **实践指导**：证实为AI内容添加“AI生成”标签是必要且有效的信任调节工具。\n- **方法创新**：展示了行为与生理传感可作为隐性的“信任探测器”，为未来人机交互系统的实时适应性设计提供新思路。\n- **理论深化**：揭示了人们对AI信息的信任判断存在“表面质量偏好”与“来源偏见”的复杂互动。\n\n### 6. 未来方向\n- 探索更细粒度的标签设计（如“AI辅助生成”）。\n- 在更自然、长期的场景中验证结论。\n- 开发基于实时生理反馈的“信任校准系统”，在用户过度信任不准确信息时发出提醒。\n\n**总结**：这项研究警示我们，AI生成的健康信息可能因“看起来更专业”而获得过高信任。强制性的来源标签能有效平衡这种风险，而我们的眼睛和身体反应早已悄悄透露了内心的信任程度。",
  "timestamp": "2025-12-16T22:32:19.551290",
  "model_name": "deepseek-reasoner"
}