#!/usr/bin/env python3
"""
é€šç”¨ä¼šè®®è®ºæ–‡å¤„ç†è„šæœ¬

æ”¯æŒ:
- ä» data/paperlists å¯¼å…¥æŒ‡å®šä¼šè®®è®ºæ–‡åˆ°æ•°æ®åº“
- ä¸ºæ‰€æœ‰æ´»è·ƒç”¨æˆ·ç”Ÿæˆæ¨èæ± 
- ç”Ÿæˆç¿»è¯‘/AIè§£è¯»/TTSå†…å®¹

ç”¨æ³•:
  python process_conference.py <conference_id> [options]
  python process_conference.py iclr2025 --import      # å¯¼å…¥è®ºæ–‡
  python process_conference.py iclr2025 --pool        # ç”Ÿæˆæ¨èæ± 
  python process_conference.py iclr2025 --content     # ç”Ÿæˆå†…å®¹
  python process_conference.py iclr2025 --all         # æ‰§è¡Œæ‰€æœ‰æ­¥éª¤
  python process_conference.py --list                 # åˆ—å‡ºå¯ç”¨ä¼šè®®
"""

import sys
import os
import json
import argparse
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional
from uuid import UUID

# æ·»åŠ backendæ ¹ç›®å½•åˆ°è·¯å¾„
backend_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(backend_root))

from sqlalchemy import select, distinct
from sqlalchemy.orm import Session
from loguru import logger

from app.db.session import SessionLocal
from app.models import Paper, UserFeedback, UserPaperRanking, PaperTranslation, PaperInterpretation
from app.services.data_ingestion.conference_import import (
    import_conference_papers,
    get_available_2025_conferences,
    SUPPORTED_2025_CONFERENCES
)
from app.services.recommendation.user_ranking_service import UserRankingService


class ConferenceProcessor:
    """é€šç”¨ä¼šè®®å¤„ç†å™¨"""
    
    def __init__(self, conference_id: str):
        self.conference_id = conference_id
        self.session: Optional[Session] = None
        self.ranking_service = None
        
    def setup_session(self):
        """è®¾ç½®æ•°æ®åº“ä¼šè¯"""
        self.session = SessionLocal()
        self.ranking_service = UserRankingService(self.session)
        
    def cleanup_session(self):
        """æ¸…ç†æ•°æ®åº“ä¼šè¯"""
        if self.session:
            self.session.close()
    
    @property
    def source_key(self) -> str:
        """è·å–æ•°æ®åº“ä¸­çš„sourceæ ‡è¯†"""
        return f"conf/{self.conference_id}"
    
    # ==================== IMPORT ====================
    
    def run_import(self) -> Dict:
        """å¯¼å…¥ä¼šè®®è®ºæ–‡åˆ°æ•°æ®åº“"""
        logger.info(f"å¼€å§‹å¯¼å…¥ä¼šè®®è®ºæ–‡: {self.conference_id}")
        
        try:
            batch = import_conference_papers(self.session, self.conference_id)
            result = {
                'success': True,
                'batch_id': str(batch.id),
                'paper_count': batch.item_count,
                'message': f"æˆåŠŸå¯¼å…¥ {batch.item_count} ç¯‡è®ºæ–‡"
            }
            logger.info(result['message'])
            return result
        except Exception as e:
            logger.error(f"å¯¼å…¥å¤±è´¥: {e}")
            return {'success': False, 'message': str(e)}
    
    # ==================== POOL GENERATION ====================
    
    def get_active_users(self) -> List[str]:
        """è·å–æ´»è·ƒç”¨æˆ·åˆ—è¡¨"""
        # ä»UserFeedbackè¡¨è·å–æœ‰åé¦ˆè¡Œä¸ºçš„ç”¨æˆ·
        feedback_users = set(self.session.execute(
            select(distinct(UserFeedback.user_id))
        ).scalars().all())
        
        # ä»UserPaperRankingè¡¨è·å–æœ‰æ’åºè¡¨çš„ç”¨æˆ·
        ranking_users = set(self.session.execute(
            select(distinct(UserPaperRanking.user_id))
        ).scalars().all())
        
        all_users = feedback_users.union(ranking_users)
        logger.info(f"æ‰¾åˆ° {len(all_users)} ä¸ªæ´»è·ƒç”¨æˆ·")
        return list(all_users)
    
    def get_conference_papers(self) -> List[UUID]:
        """è·å–è¯¥ä¼šè®®çš„æ‰€æœ‰è®ºæ–‡ID"""
        papers = self.session.execute(
            select(Paper.id).where(
                Paper.source == self.source_key
            )
        ).scalars().all()
        
        logger.info(f"æ‰¾åˆ° {len(papers)} ç¯‡ {self.conference_id} è®ºæ–‡")
        return list(papers)
    
    def check_existing_ranking(self, user_id: str) -> bool:
        """æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²æœ‰è¯¥ä¼šè®®çš„æ’åºè¡¨"""
        existing = self.session.execute(
            select(UserPaperRanking.id).where(
                UserPaperRanking.user_id == user_id,
                UserPaperRanking.source_key == self.conference_id
            )
        ).scalar_one_or_none()
        return existing is not None
    
    def run_pool_generation(self, force_update: bool = False, max_users: int = None) -> Dict:
        """ä¸ºæ‰€æœ‰æ´»è·ƒç”¨æˆ·ç”Ÿæˆæ¨èæ± """
        logger.info(f"å¼€å§‹ä¸º {self.conference_id} ç”Ÿæˆæ¨èæ± ...")
        
        paper_ids = self.get_conference_papers()
        if not paper_ids:
            return {'success': False, 'message': 'æœªæ‰¾åˆ°è¯¥ä¼šè®®çš„è®ºæ–‡ï¼Œè¯·å…ˆè¿è¡Œ --import'}
        
        users = self.get_active_users()
        if not users:
            return {'success': False, 'message': 'æœªæ‰¾åˆ°æ´»è·ƒç”¨æˆ·'}
        
        if max_users:
            users = users[:max_users]
            logger.info(f"é™åˆ¶å¤„ç†ç”¨æˆ·æ•°é‡ä¸º: {max_users}")
        
        # å¯ç”¨ä¼˜åŒ–ç‰ˆæ’åºç®—æ³•
        try:
            from app.services.recommendation.user_paper_ranking_optimized import patch_ranking_service
            patch_ranking_service()
        except ImportError:
            logger.warning("ä¼˜åŒ–ç‰ˆæ’åºæœåŠ¡ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤ç‰ˆæœ¬")
        
        results = {'total': len(users), 'success': 0, 'failed': 0, 'skipped': 0}
        
        for i, user_id in enumerate(users, 1):
            try:
                if not force_update and self.check_existing_ranking(user_id):
                    results['skipped'] += 1
                    continue
                
                success = self.ranking_service.update_user_ranking(
                    user_id=user_id,
                    source_key=self.conference_id,
                    paper_ids=paper_ids,
                    force_update=force_update
                )
                
                if success:
                    results['success'] += 1
                else:
                    results['failed'] += 1
                    
            except Exception as e:
                logger.error(f"ç”¨æˆ· {user_id} æ’åºè¡¨ç”Ÿæˆå¤±è´¥: {e}")
                results['failed'] += 1
            
            if i % 10 == 0:
                logger.info(f"è¿›åº¦: {i}/{len(users)} - æˆåŠŸ: {results['success']}, å¤±è´¥: {results['failed']}, è·³è¿‡: {results['skipped']}")
        
        results['message'] = f"å¤„ç†å®Œæˆ: æˆåŠŸ {results['success']}, å¤±è´¥ {results['failed']}, è·³è¿‡ {results['skipped']}"
        results['success_flag'] = results['failed'] == 0
        logger.info(results['message'])
        return results
    
    # ==================== CONTENT GENERATION ====================
    
    def get_papers_without_content(self, limit: int = 100) -> List[Paper]:
        """è·å–æ²¡æœ‰ç¿»è¯‘å’ŒAIè§£è¯»çš„è®ºæ–‡"""
        from sqlalchemy import text
        
        query = text("""
            SELECT p.* FROM papers p
            WHERE p.source = :source
            AND NOT EXISTS (
                SELECT 1 FROM paper_translations pt WHERE pt.paper_id = p.id
            )
            AND NOT EXISTS (
                SELECT 1 FROM paper_interpretations pi WHERE pi.paper_id = p.id
            )
            ORDER BY RANDOM()
            LIMIT :limit
        """)
        
        result = self.session.execute(query, {"source": self.source_key, "limit": limit})
        paper_rows = result.fetchall()
        
        papers = []
        for row in paper_rows:
            paper = self.session.get(Paper, row.id)
            if paper:
                # å¼ºåˆ¶åŠ è½½å±æ€§å¹¶ä»sessionåˆ†ç¦»
                _ = paper.id, paper.title, paper.summary, paper.authors, paper.categories, paper.arxiv_id
                self.session.expunge(paper)
                papers.append(paper)
        
        return papers
    
    def run_content_generation(self, steps: List[str] = None, batch_size: int = 50) -> Dict:
        """ç”Ÿæˆç¿»è¯‘/AIè§£è¯»/TTSå†…å®¹"""
        if steps is None:
            steps = ['trans', 'ai', 'tts']
        
        logger.info(f"å¼€å§‹ä¸º {self.conference_id} ç”Ÿæˆå†…å®¹: {steps}")
        
        papers = self.get_papers_without_content(limit=batch_size)
        if not papers:
            return {'success': True, 'message': 'æ‰€æœ‰è®ºæ–‡éƒ½å·²æœ‰å†…å®¹ï¼Œæ— éœ€ç”Ÿæˆ'}
        
        logger.info(f"æ‰¾åˆ° {len(papers)} ç¯‡éœ€è¦ç”Ÿæˆå†…å®¹çš„è®ºæ–‡")
        
        results = {'translations': 0, 'interpretations': 0, 'tts': 0}
        
        # ç”Ÿæˆç¿»è¯‘
        if 'trans' in steps:
            try:
                from app.services.content_generation.translation_generate_v2 import generate_translations_for_papers
                translations = generate_translations_for_papers(papers, max_workers=50)
                
                # ä¿å­˜åˆ°æ•°æ®åº“
                with SessionLocal() as save_session:
                    for paper in papers:
                        if paper.id in translations:
                            title_zh, summary_zh = translations[paper.id]
                            existing = save_session.query(PaperTranslation).filter(
                                PaperTranslation.paper_id == paper.id
                            ).first()
                            if not existing:
                                translation = PaperTranslation(
                                    paper_id=paper.id,
                                    title_zh=title_zh,
                                    summary_zh=summary_zh,
                                    model_name="deepseek-reasoner"
                                )
                                save_session.add(translation)
                                results['translations'] += 1
                    save_session.commit()
                logger.info(f"ç¿»è¯‘å®Œæˆ: {results['translations']} ç¯‡")
            except Exception as e:
                logger.error(f"ç¿»è¯‘ç”Ÿæˆå¤±è´¥: {e}")
        
        # ç”ŸæˆAIè§£è¯»
        if 'ai' in steps:
            try:
                from app.services.content_generation.ai_interpretation_generate_v2 import generate_interpretations_for_papers
                interpretations = generate_interpretations_for_papers(papers, max_workers=50)
                
                with SessionLocal() as save_session:
                    for paper in papers:
                        if paper.id in interpretations:
                            existing = save_session.query(PaperInterpretation).filter(
                                PaperInterpretation.paper_id == paper.id
                            ).first()
                            if not existing:
                                interpretation = PaperInterpretation(
                                    paper_id=paper.id,
                                    interpretation=interpretations[paper.id],
                                    language="zh",
                                    model_name="deepseek-reasoner"
                                )
                                save_session.add(interpretation)
                                results['interpretations'] += 1
                    save_session.commit()
                logger.info(f"AIè§£è¯»å®Œæˆ: {results['interpretations']} ç¯‡")
            except Exception as e:
                logger.error(f"AIè§£è¯»ç”Ÿæˆå¤±è´¥: {e}")
        
        # TTSç”Ÿæˆ (å¯é€‰)
        if 'tts' in steps:
            logger.info("TTSç”Ÿæˆæš‚æœªå®ç°é€šç”¨ç‰ˆæœ¬")
        
        results['message'] = f"å†…å®¹ç”Ÿæˆå®Œæˆ: ç¿»è¯‘ {results['translations']} ç¯‡, AIè§£è¯» {results['interpretations']} ç¯‡"
        results['success'] = True
        logger.info(results['message'])
        return results
    
    # ==================== MAIN RUNNER ====================
    
    def run(self, import_papers: bool = False, pool: bool = False, content: bool = False,
            force_update: bool = False, max_users: int = None, content_steps: List[str] = None) -> Dict:
        """è¿è¡ŒæŒ‡å®šçš„å¤„ç†æ­¥éª¤"""
        results = {}
        
        try:
            self.setup_session()
            
            if import_papers:
                results['import'] = self.run_import()
            
            if pool:
                results['pool'] = self.run_pool_generation(force_update=force_update, max_users=max_users)
            
            if content:
                results['content'] = self.run_content_generation(steps=content_steps)
            
        finally:
            self.cleanup_session()
        
        return results


def list_available_conferences():
    """åˆ—å‡ºå¯ç”¨çš„ä¼šè®®æ•°æ®"""
    print("ğŸ“‹ å¯ç”¨çš„ä¼šè®®æ•°æ®:")
    print("-" * 60)
    
    available = get_available_2025_conferences()
    
    if not available:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•ä¼šè®®æ•°æ®æ–‡ä»¶")
        return
    
    for conf in available:
        size_mb = conf['file_size'] / (1024 * 1024)
        print(f"âœ… {conf['id']:<15} {conf['name']:<20} ({size_mb:.1f} MB)")
    
    print(f"\nğŸ“Š æ€»è®¡: {len(available)} ä¸ªä¼šè®®")


def get_conference_status(conference_id: str) -> Dict:
    """è·å–ä¼šè®®å¤„ç†çŠ¶æ€"""
    with SessionLocal() as session:
        source_key = f"conf/{conference_id}"
        
        # è®ºæ–‡æ•°é‡
        paper_count = session.execute(
            select(Paper.id).where(Paper.source == source_key)
        ).scalars().all()
        
        # å·²ç¿»è¯‘æ•°é‡
        translated_count = 0
        if paper_count:
            from sqlalchemy import func
            translated_count = session.query(func.count(PaperTranslation.id)).join(
                Paper, PaperTranslation.paper_id == Paper.id
            ).filter(Paper.source == source_key).scalar() or 0
        
        # ç”¨æˆ·æ’åºè¡¨æ•°é‡
        ranking_count = session.query(UserPaperRanking).filter(
            UserPaperRanking.source_key == conference_id
        ).count()
        
        return {
            'conference_id': conference_id,
            'paper_count': len(paper_count),
            'translated_count': translated_count,
            'ranking_count': ranking_count
        }


def main():
    parser = argparse.ArgumentParser(description="é€šç”¨ä¼šè®®è®ºæ–‡å¤„ç†è„šæœ¬")
    parser.add_argument('conference', nargs='?', help='ä¼šè®®ID (å¦‚: iclr2025)')
    parser.add_argument('--list', action='store_true', help='åˆ—å‡ºå¯ç”¨ä¼šè®®')
    parser.add_argument('--status', action='store_true', help='æ˜¾ç¤ºä¼šè®®å¤„ç†çŠ¶æ€')
    parser.add_argument('--import', dest='import_papers', action='store_true', help='å¯¼å…¥è®ºæ–‡åˆ°æ•°æ®åº“')
    parser.add_argument('--pool', action='store_true', help='ç”Ÿæˆæ¨èæ± ')
    parser.add_argument('--content', action='store_true', help='ç”Ÿæˆå†…å®¹ (ç¿»è¯‘/AI/TTS)')
    parser.add_argument('--all', action='store_true', help='æ‰§è¡Œæ‰€æœ‰æ­¥éª¤')
    parser.add_argument('--force', action='store_true', help='å¼ºåˆ¶æ›´æ–°å·²å­˜åœ¨çš„æ•°æ®')
    parser.add_argument('--max-users', type=int, help='é™åˆ¶å¤„ç†çš„æœ€å¤§ç”¨æˆ·æ•°')
    parser.add_argument('--steps', nargs='+', choices=['trans', 'ai', 'tts'], 
                        default=['trans', 'ai'], help='å†…å®¹ç”Ÿæˆæ­¥éª¤')
    
    args = parser.parse_args()
    
    if args.list:
        list_available_conferences()
        return
    
    if not args.conference:
        parser.print_help()
        return
    
    if args.conference not in SUPPORTED_2025_CONFERENCES:
        print(f"âŒ ä¸æ”¯æŒçš„ä¼šè®®: {args.conference}")
        print(f"æ”¯æŒçš„ä¼šè®®: {', '.join(SUPPORTED_2025_CONFERENCES.keys())}")
        sys.exit(1)
    
    if args.status:
        status = get_conference_status(args.conference)
        print(f"ğŸ“Š {args.conference} çŠ¶æ€:")
        print(f"  è®ºæ–‡æ•°: {status['paper_count']}")
        print(f"  å·²ç¿»è¯‘: {status['translated_count']}")
        print(f"  ç”¨æˆ·æ’åºè¡¨: {status['ranking_count']}")
        return
    
    # æ‰§è¡Œå¤„ç†
    processor = ConferenceProcessor(args.conference)
    
    import_papers = args.import_papers or args.all
    pool = args.pool or args.all
    content = args.content or args.all
    
    if not (import_papers or pool or content):
        parser.print_help()
        return
    
    print(f"ğŸš€ å¼€å§‹å¤„ç†ä¼šè®®: {args.conference}")
    print(f"   æ­¥éª¤: {'å¯¼å…¥ ' if import_papers else ''}{'æ¨èæ±  ' if pool else ''}{'å†…å®¹ç”Ÿæˆ' if content else ''}")
    
    results = processor.run(
        import_papers=import_papers,
        pool=pool,
        content=content,
        force_update=args.force,
        max_users=args.max_users,
        content_steps=args.steps
    )
    
    print("\nğŸ“‹ å¤„ç†ç»“æœ:")
    for step, result in results.items():
        status = "âœ…" if result.get('success') or result.get('success_flag') else "âŒ"
        print(f"  {status} {step}: {result.get('message', result)}")


if __name__ == "__main__":
    main()
