"""
ğŸŸ¢ ACTIVE - çº¯ç¿»è¯‘æœåŠ¡ (translation_pure.py)

çº¯ç¿»è¯‘æœåŠ¡ - åªè´Ÿè´£ç¿»è¯‘åŠŸèƒ½ï¼Œä¸æ•°æ®æºè§£è€¦

ä¸»è¦å‡½æ•°ï¼š
- translate_single_paper(client: OpenAI, paper: Paper) -> Optional[Tuple[str, str]]
  è¾“å…¥ï¼šOpenAIå®¢æˆ·ç«¯ï¼Œè®ºæ–‡å¯¹è±¡
  è¾“å‡ºï¼š(ä¸­æ–‡æ ‡é¢˜, ä¸­æ–‡æ‘˜è¦)å…ƒç»„æˆ–None
  åŠŸèƒ½ï¼šç¿»è¯‘å•ç¯‡è®ºæ–‡çš„æ ‡é¢˜å’Œæ‘˜è¦

- batch_translate_papers(session: Session, papers: List[Paper], max_workers: int = 30) -> int
  è¾“å…¥ï¼šæ•°æ®åº“ä¼šè¯ï¼Œè®ºæ–‡åˆ—è¡¨ï¼Œæœ€å¤§å¹¶å‘æ•°
  è¾“å‡ºï¼šæˆåŠŸç¿»è¯‘çš„è®ºæ–‡æ•°é‡
  åŠŸèƒ½ï¼šæ‰¹é‡ç¿»è¯‘è®ºæ–‡åˆ—è¡¨ï¼ˆä¸é™äºæ¨èæ± ï¼‰

- translate_and_save_papers(session: Session, papers: List[Paper], max_workers: int = 30) -> Dict[str, int]
  è¾“å…¥ï¼šæ•°æ®åº“ä¼šè¯ï¼Œè®ºæ–‡åˆ—è¡¨ï¼Œæœ€å¤§å¹¶å‘æ•°
  è¾“å‡ºï¼šå¤„ç†ç»“æœç»Ÿè®¡å­—å…¸
  åŠŸèƒ½ï¼šç¿»è¯‘å¹¶ä¿å­˜åˆ°æ•°æ®åº“

ç¿»è¯‘æç¤ºè¯æ¨¡æ¿ï¼š
```
è¯·å°†ä»¥ä¸‹è‹±æ–‡å­¦æœ¯è®ºæ–‡çš„æ ‡é¢˜å’Œæ‘˜è¦ç¿»è¯‘æˆä¸­æ–‡ï¼š

æ ‡é¢˜ï¼š{title}
æ‘˜è¦ï¼š{abstract}

è¦æ±‚ï¼š
1. ä¿æŒå­¦æœ¯æ€§å’Œå‡†ç¡®æ€§
2. æ ‡é¢˜ç®€æ´æ˜äº†
3. æ‘˜è¦å®Œæ•´ä¼ è¾¾åŸæ„
4. ä½¿ç”¨è§„èŒƒçš„ä¸­æ–‡å­¦æœ¯è¡¨è¾¾

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¿”å›ï¼š
æ ‡é¢˜ï¼š[ä¸­æ–‡æ ‡é¢˜]
æ‘˜è¦ï¼š[ä¸­æ–‡æ‘˜è¦]
```

å¹¶å‘å¤„ç†æœºåˆ¶ï¼š
- ä½¿ç”¨ThreadPoolExecutorè¿›è¡Œå¹¶å‘ç¿»è¯‘
- åŠ¨æ€åˆ†é…è®ºæ–‡åˆ°ä¸åŒDeepSeekå®¢æˆ·ç«¯
- æ”¯æŒè‡ªå®šä¹‰å¹¶å‘æ•°ï¼ˆmax_workersï¼‰

é”™è¯¯å¤„ç†ï¼š
- å•ç¯‡è®ºæ–‡ç¿»è¯‘å¤±è´¥ä¸å½±å“å…¶ä»–è®ºæ–‡
- è¯¦ç»†çš„é”™è¯¯æ—¥å¿—è®°å½•
- è¿”å›æˆåŠŸ/å¤±è´¥ç»Ÿè®¡ä¿¡æ¯

æ•°æ®åº“æ“ä½œï¼š
- è¯»å–ï¼šPaperï¼ˆè·å–æ ‡é¢˜å’Œæ‘˜è¦ï¼‰
- å†™å…¥ï¼šPaperTranslationï¼ˆä¿å­˜ç¿»è¯‘ç»“æœï¼‰
- å»é‡ï¼šæ£€æŸ¥å·²å­˜åœ¨çš„ç¿»è¯‘è®°å½•

å¤–éƒ¨ä¾èµ–ï¼š
- app.services.llm: get_deepseek_clients, distribute_papers
- DeepSeek API: å®é™…çš„ç¿»è¯‘æœåŠ¡
- OpenAIå®¢æˆ·ç«¯ï¼šAPIè°ƒç”¨æ¥å£

ä¸translation.pyçš„åŒºåˆ«ï¼š
- translation.pyï¼šå¤„ç†æ¨èæ± ï¼Œé›†æˆAIè§£è¯»
- translation_pure.pyï¼šçº¯ç¿»è¯‘åŠŸèƒ½ï¼Œå¯å¤„ç†ä»»æ„è®ºæ–‡åˆ—è¡¨

è°ƒç”¨å…³ç³»ï¼š
- è¢«translation.pyè°ƒç”¨ï¼šå¤„ç†æ¨èæ± ç¿»è¯‘
- è¢«å€™é€‰æ± ç¿»è¯‘è„šæœ¬è°ƒç”¨ï¼šå¤„ç†å€™é€‰æ± ç¿»è¯‘
- å¯è¢«å…¶ä»–æœåŠ¡ç›´æ¥è°ƒç”¨ï¼šçµæ´»çš„ç¿»è¯‘æ¥å£
"""
from __future__ import annotations

from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, List, Optional, Tuple
from uuid import UUID

from loguru import logger
from openai import OpenAI
from sqlalchemy import select
from sqlalchemy.orm import Session

from app.models import Paper, PaperTranslation
from app.services.llm import distribute_papers, get_deepseek_clients


from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=30),
    retry=retry_if_exception_type((Exception,)),
    reraise=True
)
def translate_single_paper(client: OpenAI, paper: Paper) -> Optional[Tuple[str, str]]:
    """ç¿»è¯‘å•ç¯‡è®ºæ–‡çš„æ ‡é¢˜å’Œæ‘˜è¦ (å¸¦é‡è¯•æœºåˆ¶)"""
    
    prompt = f"""è¯·å°†ä»¥ä¸‹è‹±æ–‡å­¦æœ¯è®ºæ–‡çš„æ ‡é¢˜å’Œæ‘˜è¦ç¿»è¯‘æˆä¸­æ–‡ï¼š

æ ‡é¢˜ï¼š{paper.title}

æ‘˜è¦ï¼š{paper.summary}

è¦æ±‚ï¼š
1. ç¿»è¯‘è¦å‡†ç¡®ã€ä¸“ä¸šã€ç¬¦åˆä¸­æ–‡å­¦æœ¯è¡¨è¾¾ä¹ æƒ¯
2. ä¿æŒåŸæ–‡çš„å­¦æœ¯ä¸¥è°¨æ€§
3. ä¸“ä¸šæœ¯è¯­è¦å‡†ç¡®ç¿»è¯‘
4. æ ¼å¼ï¼š
   æ ‡é¢˜ï¼š[ç¿»è¯‘åçš„æ ‡é¢˜]
   æ‘˜è¦ï¼š[ç¿»è¯‘åçš„æ‘˜è¦]
"""
    
    try:
        response = client.chat.completions.create(
            model="deepseek-reasoner",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1000,
            temperature=0.3
        )
        
        content = response.choices[0].message.content.strip()
        
        # è§£æè¿”å›çš„å†…å®¹
        lines = content.split('\n')
        title_zh = ""
        summary_lines = []
        in_summary = False
        
        for line in lines:
            line = line.strip()
            if line.startswith('æ ‡é¢˜ï¼š'):
                title_zh = line[3:].strip()
            elif line.startswith('æ‘˜è¦ï¼š'):
                summary_lines.append(line[3:].strip())
                in_summary = True
            elif in_summary and line:
                summary_lines.append(line)
        
        summary_zh = '\n'.join(summary_lines) if summary_lines else ""
        
        if not title_zh or not summary_zh:
            logger.warning("ç¿»è¯‘ç»“æœè§£æä¸å®Œæ•´: paper_id={}", paper.id)
            return None
            
        return title_zh, summary_zh
        
    except Exception as e:
        logger.error("ç¿»è¯‘å¤±è´¥: paper_id={}, error={}", paper.id, str(e))
        return None


def batch_translate_papers(
    session: Session,
    paper_ids: List[UUID],
    max_workers: int = 30,
    force_retranslate: bool = False
) -> Dict[UUID, Tuple[str, str]]:
    """
    çº¯ç¿»è¯‘åŠŸèƒ½: æ‰¹é‡ç¿»è¯‘æŒ‡å®šçš„è®ºæ–‡åˆ—è¡¨
    
    Args:
        session: æ•°æ®åº“ä¼šè¯
        paper_ids: è®ºæ–‡IDåˆ—è¡¨
        max_workers: å¹¶å‘çº¿ç¨‹æ•°
        force_retranslate: æ˜¯å¦å¼ºåˆ¶é‡æ–°ç¿»è¯‘å·²æœ‰ç¿»è¯‘çš„è®ºæ–‡
        
    Returns:
        {paper_id: (title_zh, summary_zh)} æˆåŠŸç¿»è¯‘çš„ç»“æœ
    """
    if not paper_ids:
        logger.info("æ²¡æœ‰éœ€è¦ç¿»è¯‘çš„è®ºæ–‡")
        return {}
    
    logger.info("å¼€å§‹æ‰¹é‡ç¿»è¯‘ {} ç¯‡è®ºæ–‡", len(paper_ids))
    
    # è·å–è®ºæ–‡å¯¹è±¡
    papers_stmt = select(Paper).where(Paper.id.in_(paper_ids))
    papers = list(session.execute(papers_stmt).scalars())
    
    if not papers:
        logger.warning("æœªæ‰¾åˆ°æŒ‡å®šçš„è®ºæ–‡")
        return {}
    
    # è¿‡æ»¤å·²ç¿»è¯‘çš„è®ºæ–‡ (é™¤éå¼ºåˆ¶é‡æ–°ç¿»è¯‘)
    papers_to_translate = []
    if not force_retranslate:
        for paper in papers:
            existing = session.scalar(
                select(PaperTranslation).where(PaperTranslation.paper_id == paper.id)
            )
            if not existing or not existing.title_zh or not existing.summary_zh:
                papers_to_translate.append(paper)
        
        logger.info("è¿‡æ»¤åéœ€è¦ç¿»è¯‘çš„è®ºæ–‡: {} ç¯‡", len(papers_to_translate))
    else:
        papers_to_translate = papers
    
    if not papers_to_translate:
        logger.info("æ‰€æœ‰è®ºæ–‡éƒ½å·²æœ‰ç¿»è¯‘")
        return {}
    
    # è·å–LLMå®¢æˆ·ç«¯å¹¶åˆ†å‘è®ºæ–‡
    clients = get_deepseek_clients()
    paper_groups = distribute_papers(papers_to_translate, len(clients))
    
    translation_results = {}
    
    # å¹¶å‘ç¿»è¯‘
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_paper = {}
        
        for i, (client, paper_group) in enumerate(zip(clients, paper_groups)):
            for paper in paper_group:
                future = executor.submit(translate_single_paper, client, paper)
                future_to_paper[future] = paper
        
        # æ”¶é›†ç»“æœ
        for future in as_completed(future_to_paper):
            paper = future_to_paper[future]
            try:
                result = future.result()
                if result:
                    title_zh, summary_zh = result
                    translation_results[paper.id] = (title_zh, summary_zh)
                    logger.debug("ç¿»è¯‘æˆåŠŸ: {}", paper.title[:50])
                else:
                    logger.warning("ç¿»è¯‘å¤±è´¥: {}", paper.title[:50])
            except Exception as e:
                logger.error("ç¿»è¯‘å¼‚å¸¸: paper={}, error={}", paper.title[:50], str(e))
    
    logger.info("ç¿»è¯‘å®Œæˆ: æˆåŠŸ {} ç¯‡ï¼Œå¤±è´¥ {} ç¯‡", 
                len(translation_results), 
                len(papers_to_translate) - len(translation_results))
    
    return translation_results


def save_translation_results(
    session: Session,
    translation_results: Dict[UUID, Tuple[str, str]],
    model_name: str = "deepseek-reasoner"
) -> int:
    """
    ä¿å­˜ç¿»è¯‘ç»“æœåˆ°æ•°æ®åº“
    
    Args:
        session: æ•°æ®åº“ä¼šè¯
        translation_results: ç¿»è¯‘ç»“æœå­—å…¸
        model_name: ä½¿ç”¨çš„æ¨¡å‹åç§°
        
    Returns:
        æˆåŠŸä¿å­˜çš„æ•°é‡
    """
    if not translation_results:
        return 0
    
    saved_count = 0
    
    for paper_id, (title_zh, summary_zh) in translation_results.items():
        try:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç¿»è¯‘è®°å½•
            existing = session.scalar(
                select(PaperTranslation).where(PaperTranslation.paper_id == paper_id)
            )
            
            if existing:
                # æ›´æ–°ç°æœ‰è®°å½•
                existing.title_zh = title_zh
                existing.summary_zh = summary_zh
                existing.model_name = model_name
            else:
                # åˆ›å»ºæ–°è®°å½•
                translation = PaperTranslation(
                    paper_id=paper_id,
                    title_zh=title_zh,
                    summary_zh=summary_zh,
                    model_name=model_name
                )
                session.add(translation)
            
            saved_count += 1
            
        except Exception as e:
            logger.error("ä¿å­˜ç¿»è¯‘å¤±è´¥: paper_id={}, error={}", paper_id, str(e))
    
    try:
        session.commit()
        logger.info("ç¿»è¯‘ç»“æœä¿å­˜å®Œæˆ: {} ç¯‡", saved_count)
    except Exception as e:
        session.rollback()
        logger.error("ç¿»è¯‘ç»“æœä¿å­˜å¤±è´¥: {}", str(e))
        saved_count = 0
    
    return saved_count


def translate_and_save_papers(
    session: Session,
    paper_ids: List[UUID],
    max_workers: int = 30,
    force_retranslate: bool = False
) -> int:
    """
    ç¿»è¯‘å¹¶ä¿å­˜è®ºæ–‡ - ä¾¿æ·æ¥å£
    
    Args:
        session: æ•°æ®åº“ä¼šè¯
        paper_ids: è®ºæ–‡IDåˆ—è¡¨
        max_workers: å¹¶å‘çº¿ç¨‹æ•°
        force_retranslate: æ˜¯å¦å¼ºåˆ¶é‡æ–°ç¿»è¯‘
        
    Returns:
        æˆåŠŸå¤„ç†çš„è®ºæ–‡æ•°é‡
    """
    # æ‰¹é‡ç¿»è¯‘
    translation_results = batch_translate_papers(
        session, paper_ids, max_workers, force_retranslate
    )
    
    # ä¿å­˜ç»“æœ
    saved_count = save_translation_results(session, translation_results)
    
    return saved_count
