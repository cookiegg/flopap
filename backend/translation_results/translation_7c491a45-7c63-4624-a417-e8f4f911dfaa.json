{
  "paper_id": "7c491a45-7c63-4624-a417-e8f4f911dfaa",
  "arxiv_id": "2512.12444v1",
  "title_en": "Can GPT replace human raters? Validity and reliability of machine-generated norms for metaphors",
  "title_zh": "GPT能否取代人类评分者？机器生成隐喻规范的效度与信度评估",
  "summary_en": "As Large Language Models (LLMs) are increasingly being used in scientific research, the issue of their trustworthiness becomes crucial. In psycholinguistics, LLMs have been recently employed in automatically augmenting human-rated datasets, with promising results obtained by generating ratings for single words. Yet, performance for ratings of complex items, i.e., metaphors, is still unexplored. Here, we present the first assessment of the validity and reliability of ratings of metaphors on familiarity, comprehensibility, and imageability, generated by three GPT models for a total of 687 items gathered from the Italian Figurative Archive and three English studies. We performed a thorough validation in terms of both alignment with human data and ability to predict behavioral and electrophysiological responses. We found that machine-generated ratings positively correlated with human-generated ones. Familiarity ratings reached moderate-to-strong correlations for both English and Italian metaphors, although correlations weakened for metaphors with high sensorimotor load. Imageability showed moderate correlations in English and moderate-to-strong in Italian. Comprehensibility for English metaphors exhibited the strongest correlations. Overall, larger models outperformed smaller ones and greater human-model misalignment emerged with familiarity and imageability. Machine-generated ratings significantly predicted response times and the EEG amplitude, with a strength comparable to human ratings. Moreover, GPT ratings obtained across independent sessions were highly stable. We conclude that GPT, especially larger models, can validly and reliably replace - or augment - human subjects in rating metaphor properties. Yet, LLMs align worse with humans when dealing with conventionality and multimodal aspects of metaphorical meaning, calling for careful consideration of the nature of stimuli.",
  "summary_zh": "随着大语言模型在科学研究中的应用日益广泛，其可信度问题变得至关重要。在心理语言学领域，近期研究尝试使用大语言模型自动扩充人工评分数据集，并在单词评分生成方面取得了良好效果。然而，对于复杂语言单位（如隐喻）的评分性能尚未得到探索。本研究首次系统评估了三种GPT模型对隐喻的熟悉度、可理解性与意象性生成的评分效度与信度，共涉及从意大利语比喻库及三项英语研究中收集的687个隐喻项。我们通过双重维度进行了全面验证：一是与人类评分数据的契合度，二是对行为反应与脑电生理反应的预测能力。研究发现：机器生成评分与人类评分呈显著正相关。熟悉度评分在英语和意大利语隐喻中均达到中至强相关水平，但在感觉运动负荷较高的隐喻中相关性减弱；意象性评分在英语中呈中等相关，在意大利语中达中至强相关；英语隐喻的可理解性评分显示出最强的相关性。总体而言，更大规模的模型表现更优，但在熟悉度与意象性维度上出现更显著的人机评分差异。机器生成评分能显著预测行为反应时与脑电波幅，其预测强度与人类评分相当。此外，GPT在独立多次评分中表现出高度稳定性。我们得出结论：GPT（尤其是更大规模的模型）能够有效且可靠地替代或辅助人类受试者完成隐喻特性评分任务。然而，当涉及隐喻意义的规约性与多模态层面时，大语言模型与人类认知的契合度较低，这提示我们需要审慎考虑刺激材料的本质特性。",
  "timestamp": "2025-12-16T22:25:37.226912",
  "model_name": "deepseek-reasoner"
}