{
  "paper_id": "ce462a45-b96d-41fc-b5a5-de2a5a9ad4fd",
  "arxiv_id": "2512.12307v1",
  "title_en": "MRD: Using Physically Based Differentiable Rendering to Probe Vision Models for 3D Scene Understanding",
  "title_zh": "MRD：利用基于物理的可微分渲染探究视觉模型的三维场景理解能力",
  "summary_en": "While deep learning methods have achieved impressive success in many vision benchmarks, it remains difficult to understand and explain the representations and decisions of these models. Though vision models are typically trained on 2D inputs, they are often assumed to develop an implicit representation of the underlying 3D scene (for example, showing tolerance to partial occlusion, or the ability to reason about relative depth). Here, we introduce MRD (metamers rendered differentiably), an approach that uses physically based differentiable rendering to probe vision models' implicit understanding of generative 3D scene properties, by finding 3D scene parameters that are physically different but produce the same model activation (i.e. are model metamers). Unlike previous pixel-based methods for evaluating model representations, these reconstruction results are always grounded in physical scene descriptions. This means we can, for example, probe a model's sensitivity to object shape while holding material and lighting constant. As a proof-of-principle, we assess multiple models in their ability to recover scene parameters of geometry (shape) and bidirectional reflectance distribution function (material). The results show high similarity in model activation between target and optimized scenes, with varying visual results. Qualitatively, these reconstructions help investigate the physical scene attributes to which models are sensitive or invariant. MRD holds promise for advancing our understanding of both computer and human vision by enabling analysis of how physical scene parameters drive changes in model responses.",
  "summary_zh": "尽管深度学习方法已在众多视觉基准测试中取得显著成功，但理解和解释这些模型的表征与决策机制仍具挑战。视觉模型通常在二维输入上进行训练，但通常被认为能够形成对底层三维场景的隐式表征（例如表现出对部分遮挡的容忍度，或具备推断相对深度的能力）。本文提出MRD（可微分渲染的元匹配刺激）方法，该方法通过基于物理的可微分渲染技术，寻找在物理层面不同但能产生相同模型激活（即成为模型元匹配刺激）的三维场景参数，从而探究视觉模型对生成式三维场景属性的隐式理解。与以往基于像素的模型表征评估方法不同，该方法的重建结果始终基于物理场景描述。这意味着我们能够在固定材质与光照的条件下，专门探究模型对物体形状的敏感性。作为原理验证，我们评估了多个模型在恢复几何（形状）和双向反射分布函数（材质）等场景参数方面的能力。结果显示，目标场景与优化场景的模型激活具有高度相似性，但视觉重建结果存在差异。定性分析表明，这些重建结果有助于探究模型对哪些物理场景属性敏感或不敏感。MRD方法通过分析物理场景参数如何驱动模型响应变化，为深化计算机视觉与人类视觉的理解提供了新的研究路径。",
  "timestamp": "2025-12-16T22:25:42.663741",
  "model_name": "deepseek-reasoner"
}