{
  "paper_id": "8f90abba-eb6d-4354-ba37-b61032e8d733",
  "arxiv_id": "2512.12135v1",
  "title_en": "BaRISTA: Brain Scale Informed Spatiotemporal Representation of Human Intracranial Neural Activity",
  "title_zh": "BaRISTA：基于脑尺度信息的人类颅内神经活动时空表征方法",
  "summary_en": "Intracranial recordings have opened a unique opportunity to simultaneously measure activity across multiregional networks in the human brain. Recent works have focused on developing transformer-based neurofoundation models of such recordings that can generalize across subjects and datasets. However, these recordings exhibit highly complex spatiotemporal interactions across diverse spatial scales, from the single-channel scale to the scale of brain regions. As such, there remain critical open questions regarding how best to encode spatial information and how to design self-supervision tasks that enable the learning of brain network patterns and enhance downstream decoding performance using such high-dimensional, multiregional recordings. To allow for exploring these questions, we propose a new spatiotemporal transformer model of multiregional neural activity and a corresponding self-supervised masked latent reconstruction task, designed to enable flexibility in the spatial scale used for token encoding and masking. Applying this model on publicly available multiregional intracranial electrophysiology (iEEG) data, we demonstrate that adjusting the spatial scale for both token encoding and masked reconstruction significantly impacts downstream decoding. Further, we find that spatial encoding at larger scales than channel-level encoding, which is commonly used in existing iEEG transformer models, improves downstream decoding performance. Finally, we demonstrate that our method allows for region-level token encoding while also maintaining accurate channel-level neural reconstruction. Taken together, our modeling framework enables exploration of the spatial scales used for token encoding and masking, reveals their importance towards self-supervised pretraining of neurofoundation models of multiregional human brain activity, and enhances downstream decoding performance.",
  "summary_zh": "颅内记录技术为同步测量人脑多区域网络活动提供了独特机遇。近期研究致力于开发基于Transformer的神经基础模型，以实现跨被试与跨数据集的泛化能力。然而，这类记录数据在从单通道尺度到脑区尺度的不同空间维度上呈现出高度复杂的时空交互特性。因此，如何最优编码空间信息、如何设计自监督任务以学习脑网络模式，并利用此类高维多区域记录提升下游解码性能，仍是亟待解决的关键问题。为探索这些方向，本文提出一种针对多区域神经活动的新型时空Transformer模型及相应的自监督掩码潜在重建任务。该框架在设计上允许灵活调整用于令牌编码与掩码处理的空间尺度。通过在公开的多区域颅内脑电（iEEG）数据上应用该模型，我们证明：调整令牌编码与掩码重建的空间尺度会显著影响下游解码性能。进一步研究发现，相较于现有iEEG Transformer模型常用的通道级编码，采用更大尺度的空间编码能提升下游解码效果。最后，我们验证了该方法在实现脑区级令牌编码的同时，仍能保持精确的通道级神经重建能力。综上所述，本建模框架能够系统探索令牌编码与掩码处理的空间尺度选择，揭示了其对多区域人脑活动神经基础模型自监督预训练的重要性，并有效提升了下游解码性能。",
  "timestamp": "2025-12-16T22:25:58.149934",
  "model_name": "deepseek-reasoner"
}