{
  "paper_id": "d4fb92b0-cb0a-4019-8976-05b46b540e2d",
  "arxiv_id": "2512.12348v1",
  "title_en": "Understanding Trust Toward Human versus AI-generated Health Information through Behavioral and Physiological Sensing",
  "title_zh": "通过行为与生理传感理解对人类与AI生成健康信息的信任差异",
  "summary_en": "As AI-generated health information proliferates online and becomes increasingly indistinguishable from human-sourced information, it becomes critical to understand how people trust and label such content, especially when the information is inaccurate. We conducted two complementary studies: (1) a mixed-methods survey (N=142) employing a 2 (source: Human vs. LLM) $\\times$ 2 (label: Human vs. AI) $\\times$ 3 (type: General, Symptom, Treatment) design, and (2) a within-subjects lab study (N=40) incorporating eye-tracking and physiological sensing (ECG, EDA, skin temperature). Participants were presented with health information varying by source-label combinations and asked to rate their trust, while their gaze behavior and physiological signals were recorded. We found that LLM-generated information was trusted more than human-generated content, whereas information labeled as human was trusted more than that labeled as AI. Trust remained consistent across information types. Eye-tracking and physiological responses varied significantly by source and label. Machine learning models trained on these behavioral and physiological features predicted binary self-reported trust levels with 73% accuracy and information source with 65% accuracy. Our findings demonstrate that adding transparency labels to online health information modulates trust. Behavioral and physiological features show potential to verify trust perceptions and indicate if additional transparency is needed.",
  "summary_zh": "随着AI生成的健康信息在网络中激增，且日益难以与人类来源的信息区分，理解人们如何信任和标注此类内容变得至关重要，尤其是在信息不准确的情况下。我们进行了两项互补研究：（1）一项采用2（来源：人类 vs. 大语言模型）× 2（标注：人类 vs. AI）× 3（信息类型：通用、症状、治疗）设计的混合方法问卷调查（N=142）；（2）一项结合眼动追踪与生理传感（心电图、皮肤电活动、皮肤温度）的组内实验室研究（N=40）。研究向参与者呈现了不同来源-标注组合的健康信息，要求其评估信任度，同时记录其注视行为与生理信号。结果发现，大语言模型生成的信息比人类生成的内容获得更高信任，而被标注为人类的信息比标注为AI的信息更受信任。不同信息类型间的信任度保持稳定。眼动与生理反应因信息来源和标注不同而呈现显著差异。基于这些行为与生理特征训练的机器学习模型，能以73%的准确率预测二元自我报告的信任水平，并以65%的准确率预测信息来源。我们的研究结果表明，为在线健康信息添加透明度标注能够调节信任。行为与生理特征显示出验证信任感知及判断是否需要额外透明度的潜力。",
  "timestamp": "2025-12-16T22:25:43.023382",
  "model_name": "deepseek-reasoner"
}