{
  "paper_id": "cf93339d-50c5-4378-a951-b5f2e8a320cf",
  "arxiv_id": "2512.12224v1",
  "title_en": "Cluster-guided LLM-Based Anonymization of Software Analytics Data: Studying Privacy-Utility Trade-offs in JIT Defect Prediction",
  "title_zh": "基于聚类引导与大型语言模型的软件分析数据匿名化：即时缺陷预测中的隐私-效用权衡研究",
  "summary_en": "The increasing use of machine learning (ML) for Just-In-Time (JIT) defect prediction raises concerns about privacy leakage from software analytics data. Existing anonymization methods, such as tabular transformations and graph perturbations, often overlook contextual dependencies among software metrics, leading to suboptimal privacy-utility tradeoffs. Leveraging the contextual reasoning of Large Language Models (LLMs), we propose a cluster-guided anonymization technique that preserves contextual and statistical relationships within JIT datasets. Our method groups commits into feature-based clusters and employs an LLM to generate context-aware parameter configurations for each commit cluster, defining alpha-beta ratios and churn mixture distributions used for anonymization. Our evaluation on six projects (Cassandra, Flink, Groovy, Ignite, OpenStack, and Qt) shows that our LLM-based approach achieves privacy level 2 (IPR >= 80 percent), improving privacy by 18 to 25 percent over four state-of-the-art graph-based anonymization baselines while maintaining comparable F1 scores. Our results demonstrate that LLMs can act as adaptive anonymization engines when provided with cluster-specific statistical information about similar data points, enabling context-sensitive and privacy-preserving software analytics without compromising predictive accuracy.",
  "summary_zh": "机器学习在即时缺陷预测中的日益广泛应用，引发了对软件分析数据隐私泄露的担忧。现有的匿名化方法（如表格转换与图扰动）往往忽略软件度量指标间的上下文依赖关系，导致隐私-效用权衡效果欠佳。本研究利用大型语言模型的上下文推理能力，提出一种聚类引导的匿名化技术，以保持即时缺陷预测数据集中上下文与统计关系的完整性。该方法首先将代码提交按特征聚类，随后运用大型语言模型为每个提交簇生成上下文感知的参数配置，定义用于匿名化的α-β比例与变更混合分布。在六个开源项目（Cassandra、Flink、Groovy、Ignite、OpenStack和Qt）上的实验表明：基于大型语言模型的方法达到隐私等级2（个体隐私风险值≥80%），相较于四种先进的基于图的匿名化基线方法，隐私保护水平提升18%至25%，同时保持相当的F1分数。研究结果证明，当提供针对相似数据点的聚类统计信息时，大型语言模型可作为自适应匿名化引擎，在保障预测精度的前提下实现上下文感知的隐私保护型软件分析。",
  "timestamp": "2025-12-16T22:25:51.087967",
  "model_name": "deepseek-reasoner"
}