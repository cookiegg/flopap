{
  "paper_id": "0430f8dd-9001-46e1-ba67-214abe6f0362",
  "arxiv_id": "2512.12375v1",
  "title_en": "V-Warper: Appearance-Consistent Video Diffusion Personalization via Value Warping",
  "title_zh": "V-Warper：基于值扭曲的、外观一致性的视频扩散个性化方法",
  "summary_en": "Video personalization aims to generate videos that faithfully reflect a user-provided subject while following a text prompt. However, existing approaches often rely on heavy video-based finetuning or large-scale video datasets, which impose substantial computational cost and are difficult to scale. Furthermore, they still struggle to maintain fine-grained appearance consistency across frames. To address these limitations, we introduce V-Warper, a training-free coarse-to-fine personalization framework for transformer-based video diffusion models. The framework enhances fine-grained identity fidelity without requiring any additional video training. (1) A lightweight coarse appearance adaptation stage leverages only a small set of reference images, which are already required for the task. This step encodes global subject identity through image-only LoRA and subject-embedding adaptation. (2) A inference-time fine appearance injection stage refines visual fidelity by computing semantic correspondences from RoPE-free mid-layer query--key features. These correspondences guide the warping of appearance-rich value representations into semantically aligned regions of the generation process, with masking ensuring spatial reliability. V-Warper significantly improves appearance fidelity while preserving prompt alignment and motion dynamics, and it achieves these gains efficiently without large-scale video finetuning.",
  "summary_zh": "视频个性化旨在生成既能忠实反映用户提供的主体，又能遵循文本提示的视频。然而，现有方法通常依赖于繁重的基于视频的微调或大规模视频数据集，这带来了巨大的计算成本且难以扩展。此外，这些方法仍难以在帧间保持细粒度的外观一致性。为应对这些局限，我们提出了V-Warper，一个无需训练、从粗到精的个性化框架，适用于基于Transformer的视频扩散模型。该框架无需任何额外的视频训练即可提升细粒度的身份保真度。（1）一个轻量级的粗粒度外观适应阶段仅利用任务本身所需的一小部分参考图像。该步骤通过纯图像LoRA和主体嵌入适应来编码全局主体身份。（2）一个推理时的细粒度外观注入阶段通过计算来自无RoPE的中间层查询-键特征的语义对应关系来优化视觉保真度。这些对应关系引导将富含外观信息的“值”表示扭曲到生成过程中语义对齐的区域，并通过掩码确保空间可靠性。V-Warper在保持提示对齐和运动动态的同时，显著提升了外观保真度，并且无需大规模视频微调即可高效实现这些优势。",
  "timestamp": "2025-12-16T22:25:39.138486",
  "model_name": "deepseek-reasoner"
}