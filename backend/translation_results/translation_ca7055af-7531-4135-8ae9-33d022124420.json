{
  "paper_id": "ca7055af-7531-4135-8ae9-33d022124420",
  "arxiv_id": "2512.12208v1",
  "title_en": "A Hybrid Deep Learning Framework for Emotion Recognition in Children with Autism During NAO Robot-Mediated Interaction",
  "title_zh": "面向自闭症儿童与NAO机器人交互过程中情绪识别的混合深度学习框架",
  "summary_en": "Understanding emotional responses in children with Autism Spectrum Disorder (ASD) during social interaction remains a critical challenge in both developmental psychology and human-robot interaction. This study presents a novel deep learning pipeline for emotion recognition in autistic children in response to a name-calling event by a humanoid robot (NAO), under controlled experimental settings. The dataset comprises of around 50,000 facial frames extracted from video recordings of 15 children with ASD. A hybrid model combining a fine-tuned ResNet-50-based Convolutional Neural Network (CNN) and a three-layer Graph Convolutional Network (GCN) trained on both visual and geometric features extracted from MediaPipe FaceMesh landmarks. Emotions were probabilistically labeled using a weighted ensemble of two models: DeepFace's and FER, each contributing to soft-label generation across seven emotion classes. Final classification leveraged a fused embedding optimized via Kullback-Leibler divergence. The proposed method demonstrates robust performance in modeling subtle affective responses and offers significant promise for affective profiling of ASD children in clinical and therapeutic human-robot interaction contexts, as the pipeline effectively captures micro emotional cues in neurodivergent children, addressing a major gap in autism-specific HRI research. This work represents the first such large-scale, real-world dataset and pipeline from India on autism-focused emotion analysis using social robotics, contributing an essential foundation for future personalized assistive technologies.",
  "summary_zh": "理解自闭症谱系障碍儿童在社会互动中的情绪反应，始终是发展心理学和人机交互领域的关键挑战。本研究提出了一种新颖的深度学习流程，用于在受控实验环境下，识别自闭症儿童对人形机器人（NAO）点名事件的情绪反应。数据集包含从15名ASD儿童的视频记录中提取的约50,000帧面部图像。我们构建了一个混合模型，该模型结合了基于微调ResNet-50的卷积神经网络和一个三层图卷积网络，后者使用从MediaPipe FaceMesh特征点提取的视觉与几何特征进行训练。情绪标签通过两个模型（DeepFace和FER）的加权集成进行概率性标注，二者共同为七个情绪类别生成软标签。最终分类利用通过Kullback-Leibler散度优化的融合嵌入向量实现。所提出的方法在建模细微情感反应方面表现出鲁棒的性能，并为临床和治疗性人机交互场景中ASD儿童的情感分析提供了重要前景。该流程能有效捕捉神经多样性儿童的微观情绪线索，弥补了自闭症特异性人机交互研究中的一个主要空白。此项工作代表了印度首个利用社交机器人进行自闭症情绪分析的大规模真实世界数据集及流程，为未来个性化辅助技术奠定了重要基础。",
  "timestamp": "2025-12-16T22:25:53.786048",
  "model_name": "deepseek-reasoner"
}