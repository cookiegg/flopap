{
  "paper_id": "2b4b39d6-2f5c-4df3-bd33-f88749376d9d",
  "arxiv_id": "2512.12303v1",
  "title_en": "OMUDA: Omni-level Masking for Unsupervised Domain Adaptation in Semantic Segmentation",
  "title_zh": "OMUDA：面向语义分割无监督域适应的全层级掩码方法",
  "summary_en": "Unsupervised domain adaptation (UDA) enables semantic segmentation models to generalize from a labeled source domain to an unlabeled target domain. However, existing UDA methods still struggle to bridge the domain gap due to cross-domain contextual ambiguity, inconsistent feature representations, and class-wise pseudo-label noise. To address these challenges, we propose Omni-level Masking for Unsupervised Domain Adaptation (OMUDA), a unified framework that introduces hierarchical masking strategies across distinct representation levels. Specifically, OMUDA comprises: 1) a Context-Aware Masking (CAM) strategy that adaptively distinguishes foreground from background to balance global context and local details; 2) a Feature Distillation Masking (FDM) strategy that enhances robust and consistent feature learning through knowledge transfer from pre-trained models; and 3) a Class Decoupling Masking (CDM) strategy that mitigates the impact of noisy pseudo-labels by explicitly modeling class-wise uncertainty. This hierarchical masking paradigm effectively reduces the domain shift at the contextual, representational, and categorical levels, providing a unified solution beyond existing approaches. Extensive experiments on multiple challenging cross-domain semantic segmentation benchmarks validate the effectiveness of OMUDA. Notably, on the SYNTHIA->Cityscapes and GTA5->Cityscapes tasks, OMUDA can be seamlessly integrated into existing UDA methods and consistently achieving state-of-the-art results with an average improvement of 7%.",
  "summary_zh": "无监督域适应（UDA）能够使语义分割模型从带标注的源域泛化至无标注的目标域。然而，现有UDA方法因跨域上下文歧义、特征表示不一致以及类别级伪标签噪声等问题，仍难以有效弥合域间差异。为应对这些挑战，本文提出面向无监督域适应的全层级掩码方法（OMUDA），该统一框架通过在不同表示层级引入分层掩码策略，系统性地解决上述问题。具体而言，OMUDA包含三个核心组件：1）上下文感知掩码策略，通过自适应区分前景与背景以平衡全局上下文与局部细节；2）特征蒸馏掩码策略，借助预训练模型的知识迁移增强鲁棒且一致的特征学习；3）类别解耦掩码策略，通过对类别不确定性的显式建模减轻噪声伪标签的影响。这种分层掩码范式能有效减少上下文、表示和类别三个层面的域偏移，提供了超越现有方法的统一解决方案。在多个具有挑战性的跨域语义分割基准数据集上的大量实验验证了OMUDA的有效性。值得注意的是，在SYNTHIA→Cityscapes和GTA5→Cityscapes任务中，OMUDA可无缝集成至现有UDA方法，并以平均7%的性能提升持续取得最先进的结果。",
  "timestamp": "2025-12-16T22:25:43.939754",
  "model_name": "deepseek-reasoner"
}