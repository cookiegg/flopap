{
  "paper_id": "0758d685-5e22-4623-b2d1-283d81ed6191",
  "arxiv_id": "2512.12413v1",
  "title_en": "Understanding Critical Thinking in Generative Artificial Intelligence Use: Development, Validation, and Correlates of the Critical Thinking in AI Use Scale",
  "title_zh": "理解生成式人工智能使用中的批判性思维：《AI使用批判性思维量表》的编制、验证及相关性研究",
  "summary_en": "Generative AI tools are increasingly embedded in everyday work and learning, yet their fluency, opacity, and propensity to hallucinate mean that users must critically evaluate AI outputs rather than accept them at face value. The present research conceptualises critical thinking in AI use as a dispositional tendency to verify the source and content of AI-generated information, to understand how models work and where they fail, and to reflect on the broader implications of relying on AI. Across six studies (N = 1365), we developed and validated the 13-item critical thinking in AI use scale and mapped its nomological network. Study 1 generated and content-validated scale items. Study 2 supported a three-factor structure (Verification, Motivation, and Reflection). Studies 3, 4, and 5 confirmed this higher-order model, demonstrated internal consistency and test-retest reliability, strong factor loadings, sex invariance, and convergent and discriminant validity. Studies 3 and 4 further revealed that critical thinking in AI use was positively associated with openness, extraversion, positive trait affect, and frequency of AI use. Lastly, Study 6 demonstrated criterion validity of the scale, with higher critical thinking in AI use scores predicting more frequent and diverse verification strategies, greater veracity-judgement accuracy in a novel and naturalistic ChatGPT-powered fact-checking task, and deeper reflection about responsible AI. Taken together, the current work clarifies why and how people exercise oversight over generative AI outputs and provides a validated scale and ecologically grounded task paradigm to support theory testing, cross-group, and longitudinal research on critical engagement with generative AI outputs.",
  "summary_zh": "生成式人工智能工具日益融入日常工作与学习，但其流畅性、不透明性及产生幻觉的倾向意味着使用者必须批判性地评估AI输出，而非全盘接受。本研究将AI使用中的批判性思维概念化为一种稳定的倾向性特质，包括核查AI生成信息的来源与内容、理解模型的工作原理及其局限，并反思依赖AI的广泛影响。通过六项研究（总样本量 N = 1365），我们编制并验证了包含13个项目的《AI使用批判性思维量表》，并构建了其法理网络。研究1生成并进行了量表项目的内容效度验证。研究2支持了三因子结构（验证、动机、反思）。研究3、4、5证实了这一高阶模型，证明了量表的内部一致性、重测信度、强因子载荷、性别不变性以及聚合效度与区分效度。研究3和4进一步揭示，AI使用中的批判性思维与开放性、外向性、积极特质情感及AI使用频率呈正相关。最后，研究6证明了量表的效标效度：更高的AI使用批判性思维得分能够预测更频繁和多样化的验证策略、在一项新颖且自然的基于ChatGPT的事实核查任务中更高的真实性判断准确度，以及对负责任AI的更深入反思。综上所述，本研究阐明了人们为何及如何对生成式AI输出进行监督，并提供了一个经过验证的量表及生态效度良好的任务范式，以支持关于生成式AI输出批判性参与的理论检验、跨群体和纵向研究。",
  "timestamp": "2025-12-16T22:25:40.567073",
  "model_name": "deepseek-reasoner"
}