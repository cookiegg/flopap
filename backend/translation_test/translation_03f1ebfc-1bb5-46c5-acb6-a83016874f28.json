{
  "paper_id": "03f1ebfc-1bb5-46c5-acb6-a83016874f28",
  "arxiv_id": "2512.12154v1",
  "title_en": "Keep the Lights On, Keep the Lengths in Check: Plug-In Adversarial Detection for Time-Series LLMs in Energy Forecasting",
  "title_zh": "保持灯火通明，控制序列长度：面向能源预测时序大语言模型的即插即用对抗样本检测方法",
  "summary_en": "Accurate time-series forecasting is increasingly critical for planning and operations in low-carbon power systems. Emerging time-series large language models (TS-LLMs) now deliver this capability at scale, requiring no task-specific retraining, and are quickly becoming essential components within the Internet-of-Energy (IoE) ecosystem. However, their real-world deployment is complicated by a critical vulnerability: adversarial examples (AEs). Detecting these AEs is challenging because (i) adversarial perturbations are optimized across the entire input sequence and exploit global temporal dependencies, which renders local detection methods ineffective, and (ii) unlike traditional forecasting models with fixed input dimensions, TS-LLMs accept sequences of variable length, increasing variability that complicates detection. To address these challenges, we propose a plug-in detection framework that capitalizes on the TS-LLM's own variable-length input capability. Our method uses sampling-induced divergence as a detection signal. Given an input sequence, we generate multiple shortened variants and detect AEs by measuring the consistency of their forecasts: Benign sequences tend to produce stable predictions under sampling, whereas adversarial sequences show low forecast similarity, because perturbations optimized for a full-length sequence do not transfer reliably to shorter, differently-structured subsamples. We evaluate our approach on three representative TS-LLMs (TimeGPT, TimesFM, and TimeLLM) across three energy datasets: ETTh2 (Electricity Transformer Temperature), NI (Hourly Energy Consumption), and Consumption (Hourly Electricity Consumption and Production). Empirical results confirm strong and robust detection performance across both black-box and white-box attack scenarios, highlighting its practicality as a reliable safeguard for TS-LLM forecasting in real-world energy systems.",
  "summary_zh": "精确的时序预测对低碳电力系统的规划与运行日益关键。新兴的时序大语言模型（TS-LLMs）现已能够大规模提供这种能力，无需针对特定任务进行重新训练，正迅速成为能源物联网（IoE）生态中的核心组件。然而，其实际部署因一个关键脆弱性而变得复杂：对抗样本（AEs）。检测这些对抗样本具有挑战性，原因在于：（i）对抗性扰动在整个输入序列上被优化，并利用了全局时间依赖性，这使得局部检测方法失效；（ii）与具有固定输入维度的传统预测模型不同，TS-LLMs 接受可变长度的序列，增加了检测的复杂性。为应对这些挑战，我们提出了一种即插即用的检测框架，该框架利用了 TS-LLM 自身的可变长度输入能力。我们的方法使用采样诱导的预测分歧作为检测信号。给定一个输入序列，我们生成多个缩短的变体，并通过测量其预测的一致性来检测对抗样本：良性序列在采样下倾向于产生稳定的预测，而对抗序列则表现出较低的预测相似性，因为针对完整长度序列优化的扰动无法可靠地迁移到结构不同的较短子样本上。我们在三个具有代表性的 TS-LLM（TimeGPT、TimesFM 和 TimeLLM）上，使用三个能源数据集（ETTh2（电力变压器温度）、NI（每小时能耗）和 Consumption（每小时电力消费与生产））评估了我们的方法。实证结果证实了该方法在黑盒和白盒攻击场景下均具有强大且稳健的检测性能，凸显了其作为现实能源系统中 TS-LLM 预测可靠防护手段的实用性。",
  "timestamp": "2025-12-16T22:24:26.502062",
  "model_name": "deepseek-reasoner"
}