{
  "paper_id": "12b0ab11-0c83-4c12-b228-bbfa80f5dd45",
  "arxiv_id": "2512.12498v1",
  "title_en": "Advancing Cache-Based Few-Shot Classification via Patch-Driven Relational Gated Graph Attention",
  "title_zh": "基于图像块驱动关系门控图注意力的缓存式小样本分类方法研究",
  "summary_en": "Few-shot image classification remains difficult under limited supervision and visual domain shift. Recent cache-based adaptation approaches (e.g., Tip-Adapter) address this challenge to some extent by learning lightweight residual adapters over frozen features, yet they still inherit CLIP's tendency to encode global, general-purpose representations that are not optimally discriminative to adapt the generalist to the specialist's domain in low-data regimes. We address this limitation with a novel patch-driven relational refinement that learns cache adapter weights from intra-image patch dependencies rather than treating an image embedding as a monolithic vector. Specifically, we introduce a relational gated graph attention network that constructs a patch graph and performs edge-aware attention to emphasize informative inter-patch interactions, producing context-enriched patch embeddings. A learnable multi-aggregation pooling then composes these into compact, task-discriminative representations that better align cache keys with the target few-shot classes. Crucially, the proposed graph refinement is used only during training to distil relational structure into the cache, incurring no additional inference cost beyond standard cache lookup. Final predictions are obtained by a residual fusion of cache similarity scores with CLIP zero-shot logits. Extensive evaluations on 11 benchmarks show consistent gains over state-of-the-art CLIP adapter and cache-based baselines while preserving zero-shot efficiency. We further validate battlefield relevance by introducing an Injured vs. Uninjured Soldier dataset for casualty recognition. It is motivated by the operational need to support triage decisions within the \"platinum minutes\" and the broader \"golden hour\" window in time-critical UAV-driven search-and-rescue and combat casualty care.",
  "summary_zh": "小样本图像分类在有限监督和视觉域偏移条件下仍面临挑战。近期基于缓存的自适应方法（如Tip-Adapter）通过基于冻结特征学习轻量级残差适配器，在一定程度上缓解了这一问题。然而，这些方法仍继承了CLIP模型倾向于编码全局通用表征的特性，在低数据场景下难以实现通用模型向专业领域的最优判别性适应。为突破此局限，本文提出一种新颖的图像块驱动关系优化机制，通过挖掘图像内部块间依赖关系（而非将图像嵌入视为单一向量）来学习缓存适配器权重。具体而言，我们设计了关系门控图注意力网络：首先构建图像块关系图，继而执行边缘感知注意力以强化信息丰富的块间交互，最终生成上下文增强的图像块嵌入。随后，通过可学习的多聚合池化操作将这些嵌入融合为紧凑且具有任务判别性的表征，从而更好地将缓存键与目标小样本类别对齐。关键的是，所提出的图优化机制仅在训练阶段用于将关系结构蒸馏至缓存中，在推理阶段除标准缓存检索外不产生额外计算开销。最终预测结果通过缓存相似度分数与CLIP零样本逻辑值的残差融合获得。在11个基准数据集上的广泛实验表明，本方法在保持零样本推理效率的同时，较当前最先进的CLIP适配器及基于缓存的基线模型实现了性能的持续提升。为进一步验证战场应用价值，我们构建了\"伤员与未受伤士兵识别数据集\"用于伤亡识别研究。该数据集的建立源于实战需求：在无人机驱动的紧急搜救与战伤救护任务中，为\"白金十分钟\"及更广泛的\"黄金一小时\"时间窗口内的伤员分诊决策提供技术支持。",
  "timestamp": "2025-12-16T22:23:57.124493",
  "model_name": "deepseek-reasoner"
}